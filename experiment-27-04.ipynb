{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import itertools\n",
    "import copy\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Set up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Short description##\n",
    "\n",
    "BSc thesis description:\n",
    "\n",
    "The title of the thesis was 'The Empirical Inefficiency of Equilibria in Coordination games on Social Networks'. \n In the thesis I explore a case of algorithmic game theory on Facebook and model-based networks. \n For more information regarding the theory and methodology, please contact me directly.",
    "The data from real-world Facebook networks was collected via the Netvizz application version in the autumn of 2014\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data pre-processing to a graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fbgraph=open('somenetwork.gdf','r').read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#split to two lists: nodes and edges\n",
    "\n",
    "nodes=[]\n",
    "\n",
    "for node in fbgraph:\n",
    "    if node!='edgedef>node1 VARCHAR,node2 VARCHAR':\n",
    "        nodes.append(node)\n",
    "    else:\n",
    "        break\n",
    "        \n",
    "edges=[i for i in fbgraph if i not in nodes]\n",
    "edges = edges[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#store nodeIDs (type string) only \n",
    "\n",
    "nodeIDs=[]\n",
    "for i in nodes:\n",
    "    nodeID=i.split(',',1)[0]\n",
    "    nodeIDs.append(nodeID)\n",
    "nodeIDs = nodeIDs[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#make dictionary with only keys (nodeIDs)\n",
    "\n",
    "grdict={x:[] for x in nodeIDs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Add edges between nodeIDs (keys) and their neighbors (values)\n",
    "\n",
    "for i in grdict.keys():\n",
    "    for j in edges: \n",
    "        if i==j.split(',',1)[0]:\n",
    "            grdict[i].append(j.split(',',1)[1])\n",
    "            grdict[j.split(',',1)[1]].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# FOR CLARITY - give nodes new names: integers\n",
    "\n",
    "new_names={}\n",
    "for i,j in enumerate(grdict.keys()):\n",
    "    new_names[j]=i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#change node IDs in dictionary values to integer values\n",
    "\n",
    "for e, k in enumerate(grdict.values()):\n",
    "    #for every node in neighbor list\n",
    "    for e2, i in enumerate(k):\n",
    "        for j in new_names.keys():\n",
    "            if i==j:\n",
    "                grdict.values()[e][e2]=new_names[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#change node IDs in dictionary keys\n",
    "\n",
    "for i in grdict.keys():\n",
    "    for j in new_names.keys():\n",
    "        if i==j:\n",
    "            grdict[new_names[j]] = grdict.pop(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPERIMENTS###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sizes = [1,3,4,5,6,7,8,9,10,2] # sizes ok K set\n",
    "\n",
    "#already did with 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# |K| = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### EXPERIMENT K size = 1\n",
    "\n",
    "iteration = 1\n",
    "# for j in xrange(len(sizes)): #for different sizes of k\n",
    "    # initialize dataframe k | k size | PoA\n",
    "data = pd.DataFrame(columns=('k', 'k size', 'PoA'))\n",
    "    ### 1\n",
    "\n",
    "    #random K set\n",
    "    #k = random.sample(xrange(len(nodeIDs)), sizes[j])\n",
    "\n",
    "for i in xrange(200):\n",
    "    ### 1\n",
    "\n",
    "    #random K set\n",
    "    k = random.sample(xrange(len(nodeIDs)), sizes[0])\n",
    "\n",
    "    ### 2\n",
    "\n",
    "    #ADD ALL CALCULATIONS FOR THIS k\n",
    "    grd = grdict.copy()\n",
    "    gdc = copy.copy(grd)\n",
    "    # make dictionary into graph\n",
    "    grd = nx.to_networkx_graph(grd)\n",
    "\n",
    "    ############## START STRATEGY DISTRIBUTION ###########\n",
    "\n",
    "    ### Initialize Identity matrix - everyone has their own strategy\n",
    "\n",
    "    strategies = np.identity(len(nodeIDs))\n",
    "\n",
    "    ### Make a copy of real graph to find strategy distribution (because we'll need to delete some edges)\n",
    "\n",
    "    H = grd.copy()\n",
    "\n",
    "    ### For strategy distribution disregard edges between nodes in k\n",
    "\n",
    "    #all possible edge combinations between the k_nodes\n",
    "    knode_pedges=list(itertools.combinations(k, 2))\n",
    "\n",
    "    #Identify if the nodes have edges among each other and store them\n",
    "    edges_between_k=[]\n",
    "    for pedge in knode_pedges:\n",
    "        for edge in H.edges():\n",
    "            if set(pedge)==set(edge):\n",
    "                edges_between_k.append(pedge)\n",
    "\n",
    "    # For the strategy distribution delete the edges between k in a duplicate H of our real graph grd! \n",
    "    H.remove_edges_from(edges_between_k)\n",
    "\n",
    "    ### Find neighborhood of range = 2 for nodes in k and assign them the strategy of that node\n",
    "\n",
    "    #Check how many nodes have neighborhood of 2 less than a 100\n",
    "\n",
    "    for i in xrange(len(k)):\n",
    "        for j in nx.ego_graph(H, k[i], 2).nodes():\n",
    "            if j not in k:\n",
    "                strategies[j][k[i]]=1\n",
    "\n",
    "    np.where(strategies[4] == 1)[0].tolist()\n",
    "\n",
    "    ### STRATEGY ASSIGNMENT TO NODES\n",
    "\n",
    "    #to avoid confusion attribute will be called plays rather than strategies (to separate from strategy matrix)\n",
    "\n",
    "    for i in xrange(len(nodeIDs)):\n",
    "        key=\"plays\"\n",
    "        #step of assigining attributes\n",
    "        grd.node[i].setdefault(key, np.where(strategies[i] == 1)[0].tolist()) \n",
    "\n",
    "    gego = grd.copy() # duplicate graph for 'OPTIMAL' calculations later\n",
    "\n",
    "    ### Create ATTRIBUTES in graph: neighbors, current_play, possible_play (to find what is my payoff \n",
    "    #                                                                       if I play this strategy)\n",
    "\n",
    "    for i in xrange(len(nodeIDs)):\n",
    "        # step of assigining attributes\n",
    "        grd.node[i].setdefault(\"neighbors\", gdc[i])\n",
    "        # everybody starts at their own strategy; 'possible_play' attribute for strategy update\n",
    "        grd.node[i].setdefault(\"current_play\", i)\n",
    "        grd.node[i].setdefault(\"possible_play\", i)\n",
    "\n",
    "    ### UPDATE STRATEGIES ### \n",
    "\n",
    "    # the idea is to have two strategy lists that will be compared after every iteration through all the nodes\n",
    "    # when the lists are identical, no player will switch strategies -> hence, Nash equilibrium\n",
    "\n",
    "\n",
    "    # Initialize two lists to compare \n",
    "    past_strategies = []\n",
    "    new_strategies = []\n",
    "    for i in xrange(len(nodeIDs)):\n",
    "        new_strategies.append(grd.node[i]['current_play'])\n",
    "        past_strategies.append(0)\n",
    "\n",
    "\n",
    "    ### WHILE LOOP TO FIND BEST STRATEGIES ###\n",
    "\n",
    "\n",
    "    i = 0\n",
    "    while past_strategies != new_strategies:\n",
    "        past_strategies = copy.copy(new_strategies)\n",
    "        for inode in xrange(len(nodeIDs)):\n",
    "            # current payoff initialization\n",
    "            curr_payoff = 0\n",
    "            # possible payoff/list of payoffs initialize for every node\n",
    "            pp = 0\n",
    "            pps = []\n",
    "\n",
    "            # CURRENT payoff\n",
    "            for neighbor in xrange(len(grd.node[inode]['neighbors'])):\n",
    "                if grd.node[grd.node[inode]['neighbors'][neighbor]]['current_play'] == grd.node[inode]['current_play']:\n",
    "                    curr_payoff += 1\n",
    "\n",
    "            # POSSIBLE payoff\n",
    "            for strategy in xrange(len(grd.node[inode]['plays'])):\n",
    "                grd.node[inode]['possible_play'] = grd.node[inode]['plays'][strategy]\n",
    "                for neighbor in xrange(len(grd.node[inode]['neighbors'])):\n",
    "                    if grd.node[grd.node[inode]['neighbors'][neighbor]]['current_play'] == grd.node[inode]['possible_play']:\n",
    "                         pp += 1\n",
    "                pps.append(pp)\n",
    "                pp = 0\n",
    "\n",
    "            # Find strategy giving best payoff and update 'current_play' according to it\n",
    "            if np.max(pps) > curr_payoff:\n",
    "                # randomize strategy if max payoffs repeat\n",
    "                max_payoff_indices = [i for i, x in enumerate(pps) if x == max(pps)]\n",
    "                random_index = random.choice(max_payoff_indices)\n",
    "                # assign new strategy\n",
    "                grd.node[inode]['current_play'] = grd.node[inode]['plays'][random_index]\n",
    "                new_strategies[inode] = grd.node[inode]['current_play']\n",
    "\n",
    "    ### CALCULATE SOCIAL WELFARE ###\n",
    "\n",
    "\n",
    "    # initialize list with all players' payoffs\n",
    "    ind_payoffs = []\n",
    "    for inode in xrange(len(nodeIDs)):\n",
    "        ind_payoff = 0\n",
    "        for neighbor in xrange(len(grd.node[inode]['neighbors'])):\n",
    "            if grd.node[grd.node[inode]['neighbors'][neighbor]]['current_play'] == grd.node[inode]['current_play']:\n",
    "                ind_payoff += 1\n",
    "        ind_payoffs.append(ind_payoff)\n",
    "\n",
    "    social_welfare = sum(ind_payoffs)\n",
    "\n",
    "    ### OPTIMAL WELFARE APPROXIMATION ###\n",
    "\n",
    "    source_neighborhoods = []\n",
    "\n",
    "    # choose source with biggest ego_network\n",
    "    for source in xrange(len(k)):\n",
    "        source_neighborhoods.append(len(nx.ego_graph(gego, k[source], 2).nodes()))\n",
    "\n",
    "    for node in xrange(len(nodeIDs)):\n",
    "        gego.node[node][\"neighbors\"] = gdc[node]\n",
    "        if node in nx.ego_graph(gego, np.max(source_neighborhoods), 2).nodes():\n",
    "            # every node in ego graph gets only one strategy (source's strategy)\n",
    "            gego.node[node][\"current_play\"] = k[np.argmax(source_neighborhoods)]\n",
    "            gego.node[node][\"possible_play\"] = k[np.argmax(source_neighborhoods)]\n",
    "            gego.node[node][\"plays\"] = [k[np.argmax(source_neighborhoods)]]\n",
    "        elif node not in nx.ego_graph(gego, np.max(source_neighborhoods), 2).nodes():\n",
    "        #    # prepare for best response\n",
    "            gego.node[node][\"current_play\"] = node\n",
    "            gego.node[node][\"possible_play\"] = node\n",
    "\n",
    "    opt_past_strategies = [] # Initialize two lists to compare \n",
    "    opt_new_strategies = []\n",
    "    for i in xrange(len(nodeIDs)):\n",
    "        opt_new_strategies.append(gego.node[i]['current_play'])\n",
    "        opt_past_strategies.append(0)\n",
    "\n",
    "\n",
    "    ### While loop to find best strategies ###\n",
    "\n",
    "\n",
    "    while opt_past_strategies != opt_new_strategies:\n",
    "        opt_past_strategies = copy.copy(opt_new_strategies)\n",
    "        for inode in xrange(len(nodeIDs)):\n",
    "            # current payoff initialization\n",
    "            curr_payoff = 0\n",
    "            # possible payoff/list of payoffs initialize for every node\n",
    "            pp = 0\n",
    "            pps = []\n",
    "\n",
    "            # CURRENT payoff\n",
    "            for neighbor in xrange(len(gego.node[inode]['neighbors'])):\n",
    "                if gego.node[gego.node[inode]['neighbors'][neighbor]]['current_play'] == gego.node[inode]['current_play']:\n",
    "                    curr_payoff += 1\n",
    "\n",
    "            # POSSIBLE payoff\n",
    "            for strategy in xrange(len(gego.node[inode]['plays'])):\n",
    "                gego.node[inode]['possible_play'] = gego.node[inode]['plays'][strategy]\n",
    "                for neighbor in xrange(len(gego.node[inode]['neighbors'])):\n",
    "                    if gego.node[gego.node[inode]['neighbors'][neighbor]]['current_play'] == gego.node[inode]['possible_play']:\n",
    "                         pp += 1\n",
    "                pps.append(pp)\n",
    "                pp = 0\n",
    "\n",
    "            # Find strategy giving best payoff and update 'current_play' according to it\n",
    "            if np.max(pps) > curr_payoff:\n",
    "                # randomize strategy if max payoffs repeat\n",
    "                max_payoff_indices = [i for i, x in enumerate(pps) if x == max(pps)]\n",
    "                random_index = random.choice(max_payoff_indices)\n",
    "                # assign new strategy\n",
    "                gego.node[inode]['current_play'] = gego.node[inode]['plays'][random_index]\n",
    "                opt_new_strategies[inode] = gego.node[inode]['current_play']\n",
    "\n",
    "    ### CALCULATE SOCIAL WELFARE ###\n",
    "\n",
    "\n",
    "    # initialize list with all players' payoffs\n",
    "    opt_ind_payoffs = []\n",
    "    for inode in xrange(len(nodeIDs)):\n",
    "        opt_ind_payoff = 0\n",
    "        for neighbor in xrange(len(gego.node[inode]['neighbors'])):\n",
    "            if gego.node[gego.node[inode]['neighbors'][neighbor]]['current_play'] == gego.node[inode]['current_play']:\n",
    "                opt_ind_payoff += 1\n",
    "        opt_ind_payoffs.append(opt_ind_payoff)\n",
    "\n",
    "    opt_social_welfare = sum(opt_ind_payoffs)\n",
    "\n",
    "    if float(social_welfare) != 0:\n",
    "        PoA = float(opt_social_welfare) / float(social_welfare)\n",
    "    elif float(social_welfare) == 0:\n",
    "        PoA = float('inf')\n",
    "\n",
    "    ### 3\n",
    "    # add data to dataframe k | k size | PoA\n",
    "    df2 = pd.DataFrame([[k, len(k), social_welfare, opt_social_welfare, PoA ]], columns=('k', 'k size', 'SW', 'reasonable SW', 'PoA'))\n",
    "    frames = [data, df2]\n",
    "    data = pd.concat(frames)\n",
    "    iteration += 1\n",
    "    print iteration\n",
    "data.to_csv('FB4-random-k%s.csv' %str(len(k)), encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# |K| = 3 #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### EXPERIMENT K size = 3\n",
    "\n",
    "# for j in xrange(len(sizes)): #for different sizes of k\n",
    "    # initialize dataframe k | k size | PoA\n",
    "data = pd.DataFrame(columns=('k', 'k size', 'PoA'))\n",
    "    ### 1\n",
    "\n",
    "    #random K set\n",
    "    #k = random.sample(xrange(len(nodeIDs)), sizes[j])\n",
    "\n",
    "for i in xrange(200):\n",
    "    ### 1\n",
    "\n",
    "    #random K set\n",
    "    k = random.sample(xrange(len(nodeIDs)), sizes[1])\n",
    "\n",
    "    ### 2\n",
    "\n",
    "    #ADD ALL CALCULATIONS FOR THIS k\n",
    "    grd = grdict.copy()\n",
    "    gdc = copy.copy(grd)\n",
    "    # make dictionary into graph\n",
    "    grd = nx.to_networkx_graph(grd)\n",
    "\n",
    "    ############## START STRATEGY DISTRIBUTION ###########\n",
    "\n",
    "    ### Initialize Identity matrix - everyone has their own strategy\n",
    "\n",
    "    strategies = np.identity(len(nodeIDs))\n",
    "\n",
    "    ### Make a copy of real graph to find strategy distribution (because we'll need to delete some edges)\n",
    "\n",
    "    H = grd.copy()\n",
    "\n",
    "    ### For strategy distribution disregard edges between nodes in k\n",
    "\n",
    "    #all possible edge combinations between the k_nodes\n",
    "    knode_pedges=list(itertools.combinations(k, 2))\n",
    "\n",
    "    #Identify if the nodes have edges among each other and store them\n",
    "    edges_between_k=[]\n",
    "    for pedge in knode_pedges:\n",
    "        for edge in H.edges():\n",
    "            if set(pedge)==set(edge):\n",
    "                edges_between_k.append(pedge)\n",
    "\n",
    "    # For the strategy distribution delete the edges between k in a duplicate H of our real graph grd! \n",
    "    H.remove_edges_from(edges_between_k)\n",
    "\n",
    "    ### Find neighborhood of range = 2 for nodes in k and assign them the strategy of that node\n",
    "\n",
    "    #Check how many nodes have neighborhood of 2 less than a 100\n",
    "\n",
    "    for i in xrange(len(k)):\n",
    "        for j in nx.ego_graph(H, k[i], 2).nodes():\n",
    "            if j not in k:\n",
    "                strategies[j][k[i]]=1\n",
    "\n",
    "    np.where(strategies[4] == 1)[0].tolist()\n",
    "\n",
    "    ### STRATEGY ASSIGNMENT TO NODES\n",
    "\n",
    "    #to avoid confusion attribute will be called plays rather than strategies (to separate from strategy matrix)\n",
    "\n",
    "    for i in xrange(len(nodeIDs)):\n",
    "        key=\"plays\"\n",
    "        #step of assigining attributes\n",
    "        grd.node[i].setdefault(key, np.where(strategies[i] == 1)[0].tolist()) \n",
    "\n",
    "    gego = grd.copy() # duplicate graph for 'OPTIMAL' calculations later\n",
    "\n",
    "    ### Create ATTRIBUTES in graph: neighbors, current_play, possible_play (to find what is my payoff \n",
    "    #                                                                       if I play this strategy)\n",
    "\n",
    "    for i in xrange(len(nodeIDs)):\n",
    "        # step of assigining attributes\n",
    "        grd.node[i].setdefault(\"neighbors\", gdc[i])\n",
    "        # everybody starts at their own strategy; 'possible_play' attribute for strategy update\n",
    "        grd.node[i].setdefault(\"current_play\", i)\n",
    "        grd.node[i].setdefault(\"possible_play\", i)\n",
    "\n",
    "    ### UPDATE STRATEGIES ### \n",
    "\n",
    "    # the idea is to have two strategy lists that will be compared after every iteration through all the nodes\n",
    "    # when the lists are identical, no player will switch strategies -> hence, Nash equilibrium\n",
    "\n",
    "\n",
    "    # Initialize two lists to compare \n",
    "    past_strategies = []\n",
    "    new_strategies = []\n",
    "    for i in xrange(len(nodeIDs)):\n",
    "        new_strategies.append(grd.node[i]['current_play'])\n",
    "        past_strategies.append(0)\n",
    "\n",
    "\n",
    "    ### WHILE LOOP TO FIND BEST STRATEGIES ###\n",
    "\n",
    "\n",
    "    i = 0\n",
    "    while past_strategies != new_strategies:\n",
    "        past_strategies = copy.copy(new_strategies)\n",
    "        for inode in xrange(len(nodeIDs)):\n",
    "            # current payoff initialization\n",
    "            curr_payoff = 0\n",
    "            # possible payoff/list of payoffs initialize for every node\n",
    "            pp = 0\n",
    "            pps = []\n",
    "\n",
    "            # CURRENT payoff\n",
    "            for neighbor in xrange(len(grd.node[inode]['neighbors'])):\n",
    "                if grd.node[grd.node[inode]['neighbors'][neighbor]]['current_play'] == grd.node[inode]['current_play']:\n",
    "                    curr_payoff += 1\n",
    "\n",
    "            # POSSIBLE payoff\n",
    "            for strategy in xrange(len(grd.node[inode]['plays'])):\n",
    "                grd.node[inode]['possible_play'] = grd.node[inode]['plays'][strategy]\n",
    "                for neighbor in xrange(len(grd.node[inode]['neighbors'])):\n",
    "                    if grd.node[grd.node[inode]['neighbors'][neighbor]]['current_play'] == grd.node[inode]['possible_play']:\n",
    "                         pp += 1\n",
    "                pps.append(pp)\n",
    "                pp = 0\n",
    "\n",
    "            # Find strategy giving best payoff and update 'current_play' according to it\n",
    "            if np.max(pps) > curr_payoff:\n",
    "                # randomize strategy if max payoffs repeat\n",
    "                max_payoff_indices = [i for i, x in enumerate(pps) if x == max(pps)]\n",
    "                random_index = random.choice(max_payoff_indices)\n",
    "                # assign new strategy\n",
    "                grd.node[inode]['current_play'] = grd.node[inode]['plays'][random_index]\n",
    "                new_strategies[inode] = grd.node[inode]['current_play']\n",
    "\n",
    "    ### CALCULATE SOCIAL WELFARE ###\n",
    "\n",
    "\n",
    "    # initialize list with all players' payoffs\n",
    "    ind_payoffs = []\n",
    "    for inode in xrange(len(nodeIDs)):\n",
    "        ind_payoff = 0\n",
    "        for neighbor in xrange(len(grd.node[inode]['neighbors'])):\n",
    "            if grd.node[grd.node[inode]['neighbors'][neighbor]]['current_play'] == grd.node[inode]['current_play']:\n",
    "                ind_payoff += 1\n",
    "        ind_payoffs.append(ind_payoff)\n",
    "\n",
    "    social_welfare = sum(ind_payoffs)\n",
    "\n",
    "    ### OPTIMAL WELFARE APPROXIMATION ###\n",
    "\n",
    "    source_neighborhoods = []\n",
    "\n",
    "    # choose source with biggest ego_network\n",
    "    for source in xrange(len(k)):\n",
    "        source_neighborhoods.append(len(nx.ego_graph(gego, k[source], 2).nodes()))\n",
    "\n",
    "    for node in xrange(len(nodeIDs)):\n",
    "        gego.node[node][\"neighbors\"] = gdc[node]\n",
    "        if node in nx.ego_graph(gego, np.max(source_neighborhoods), 2).nodes():\n",
    "            # every node in ego graph gets only one strategy (source's strategy)\n",
    "            gego.node[node][\"current_play\"] = k[np.argmax(source_neighborhoods)]\n",
    "            gego.node[node][\"possible_play\"] = k[np.argmax(source_neighborhoods)]\n",
    "            gego.node[node][\"plays\"] = [k[np.argmax(source_neighborhoods)]]\n",
    "        elif node not in nx.ego_graph(gego, np.max(source_neighborhoods), 2).nodes():\n",
    "        #    # prepare for best response\n",
    "            gego.node[node][\"current_play\"] = node\n",
    "            gego.node[node][\"possible_play\"] = node\n",
    "\n",
    "    opt_past_strategies = [] # Initialize two lists to compare \n",
    "    opt_new_strategies = []\n",
    "    for i in xrange(len(nodeIDs)):\n",
    "        opt_new_strategies.append(gego.node[i]['current_play'])\n",
    "        opt_past_strategies.append(0)\n",
    "\n",
    "\n",
    "    ### While loop to find best strategies ###\n",
    "\n",
    "\n",
    "    while opt_past_strategies != opt_new_strategies:\n",
    "        opt_past_strategies = copy.copy(opt_new_strategies)\n",
    "        for inode in xrange(len(nodeIDs)):\n",
    "            # current payoff initialization\n",
    "            curr_payoff = 0\n",
    "            # possible payoff/list of payoffs initialize for every node\n",
    "            pp = 0\n",
    "            pps = []\n",
    "\n",
    "            # CURRENT payoff\n",
    "            for neighbor in xrange(len(gego.node[inode]['neighbors'])):\n",
    "                if gego.node[gego.node[inode]['neighbors'][neighbor]]['current_play'] == gego.node[inode]['current_play']:\n",
    "                    curr_payoff += 1\n",
    "\n",
    "            # POSSIBLE payoff\n",
    "            for strategy in xrange(len(gego.node[inode]['plays'])):\n",
    "                gego.node[inode]['possible_play'] = gego.node[inode]['plays'][strategy]\n",
    "                for neighbor in xrange(len(gego.node[inode]['neighbors'])):\n",
    "                    if gego.node[gego.node[inode]['neighbors'][neighbor]]['current_play'] == gego.node[inode]['possible_play']:\n",
    "                         pp += 1\n",
    "                pps.append(pp)\n",
    "                pp = 0\n",
    "\n",
    "            # Find strategy giving best payoff and update 'current_play' according to it\n",
    "            if np.max(pps) > curr_payoff:\n",
    "                # randomize strategy if max payoffs repeat\n",
    "                max_payoff_indices = [i for i, x in enumerate(pps) if x == max(pps)]\n",
    "                random_index = random.choice(max_payoff_indices)\n",
    "                # assign new strategy\n",
    "                gego.node[inode]['current_play'] = gego.node[inode]['plays'][random_index]\n",
    "                opt_new_strategies[inode] = gego.node[inode]['current_play']\n",
    "\n",
    "    ### CALCULATE SOCIAL WELFARE ###\n",
    "\n",
    "\n",
    "    # initialize list with all players' payoffs\n",
    "    opt_ind_payoffs = []\n",
    "    for inode in xrange(len(nodeIDs)):\n",
    "        opt_ind_payoff = 0\n",
    "        for neighbor in xrange(len(gego.node[inode]['neighbors'])):\n",
    "            if gego.node[gego.node[inode]['neighbors'][neighbor]]['current_play'] == gego.node[inode]['current_play']:\n",
    "                opt_ind_payoff += 1\n",
    "        opt_ind_payoffs.append(opt_ind_payoff)\n",
    "\n",
    "    opt_social_welfare = sum(opt_ind_payoffs)\n",
    "\n",
    "    if float(social_welfare) != 0:\n",
    "        PoA = float(opt_social_welfare) / float(social_welfare)\n",
    "    elif float(social_welfare) == 0:\n",
    "        PoA = float('inf')\n",
    "\n",
    "    ### 3\n",
    "    # add data to dataframe k | k size | PoA\n",
    "    df2 = pd.DataFrame([[k, len(k), social_welfare, opt_social_welfare, PoA ]], columns=('k', 'k size', 'SW', 'reasonable SW', 'PoA'))\n",
    "    frames = [data, df2]\n",
    "    data = pd.concat(frames)\n",
    "data.to_csv('FB4-random-k%s.csv' %str(len(k)), encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# |K|=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### EXPERIMENT K size = 4\n",
    "\n",
    "sizes = [1,3,4,5,6,7,8,9,10]\n",
    "# for j in xrange(len(sizes)): #for different sizes of k\n",
    "    # initialize dataframe k | k size | PoA\n",
    "data = pd.DataFrame(columns=('k', 'k size', 'PoA'))\n",
    "    ### 1\n",
    "\n",
    "    #random K set\n",
    "    #k = random.sample(xrange(len(nodeIDs)), sizes[j])\n",
    "\n",
    "for i in xrange(200):\n",
    "    ### 1\n",
    "\n",
    "    #random K set\n",
    "    k = random.sample(xrange(len(nodeIDs)), sizes[2])\n",
    "\n",
    "    ### 2\n",
    "\n",
    "    #ADD ALL CALCULATIONS FOR THIS k\n",
    "    grd = grdict.copy()\n",
    "    gdc = copy.copy(grd)\n",
    "    # make dictionary into graph\n",
    "    grd = nx.to_networkx_graph(grd)\n",
    "\n",
    "    ############## START STRATEGY DISTRIBUTION ###########\n",
    "\n",
    "    ### Initialize Identity matrix - everyone has their own strategy\n",
    "\n",
    "    strategies = np.identity(len(nodeIDs))\n",
    "\n",
    "    ### Make a copy of real graph to find strategy distribution (because we'll need to delete some edges)\n",
    "\n",
    "    H = grd.copy()\n",
    "\n",
    "    ### For strategy distribution disregard edges between nodes in k\n",
    "\n",
    "    #all possible edge combinations between the k_nodes\n",
    "    knode_pedges=list(itertools.combinations(k, 2))\n",
    "\n",
    "    #Identify if the nodes have edges among each other and store them\n",
    "    edges_between_k=[]\n",
    "    for pedge in knode_pedges:\n",
    "        for edge in H.edges():\n",
    "            if set(pedge)==set(edge):\n",
    "                edges_between_k.append(pedge)\n",
    "\n",
    "    # For the strategy distribution delete the edges between k in a duplicate H of our real graph grd! \n",
    "    H.remove_edges_from(edges_between_k)\n",
    "\n",
    "    ### Find neighborhood of range = 2 for nodes in k and assign them the strategy of that node\n",
    "\n",
    "    #Check how many nodes have neighborhood of 2 less than a 100\n",
    "\n",
    "    for i in xrange(len(k)):\n",
    "        for j in nx.ego_graph(H, k[i], 2).nodes():\n",
    "            if j not in k:\n",
    "                strategies[j][k[i]]=1\n",
    "\n",
    "    np.where(strategies[4] == 1)[0].tolist()\n",
    "\n",
    "    ### STRATEGY ASSIGNMENT TO NODES\n",
    "\n",
    "    #to avoid confusion attribute will be called plays rather than strategies (to separate from strategy matrix)\n",
    "\n",
    "    for i in xrange(len(nodeIDs)):\n",
    "        key=\"plays\"\n",
    "        #step of assigining attributes\n",
    "        grd.node[i].setdefault(key, np.where(strategies[i] == 1)[0].tolist()) \n",
    "\n",
    "    gego = grd.copy() # duplicate graph for 'OPTIMAL' calculations later\n",
    "\n",
    "    ### Create ATTRIBUTES in graph: neighbors, current_play, possible_play (to find what is my payoff \n",
    "    #                                                                       if I play this strategy)\n",
    "\n",
    "    for i in xrange(len(nodeIDs)):\n",
    "        # step of assigining attributes\n",
    "        grd.node[i].setdefault(\"neighbors\", gdc[i])\n",
    "        # everybody starts at their own strategy; 'possible_play' attribute for strategy update\n",
    "        grd.node[i].setdefault(\"current_play\", i)\n",
    "        grd.node[i].setdefault(\"possible_play\", i)\n",
    "\n",
    "    ### UPDATE STRATEGIES ### \n",
    "\n",
    "    # the idea is to have two strategy lists that will be compared after every iteration through all the nodes\n",
    "    # when the lists are identical, no player will switch strategies -> hence, Nash equilibrium\n",
    "\n",
    "\n",
    "    # Initialize two lists to compare \n",
    "    past_strategies = []\n",
    "    new_strategies = []\n",
    "    for i in xrange(len(nodeIDs)):\n",
    "        new_strategies.append(grd.node[i]['current_play'])\n",
    "        past_strategies.append(0)\n",
    "\n",
    "\n",
    "    ### WHILE LOOP TO FIND BEST STRATEGIES ###\n",
    "\n",
    "\n",
    "    i = 0\n",
    "    while past_strategies != new_strategies:\n",
    "        past_strategies = copy.copy(new_strategies)\n",
    "        for inode in xrange(len(nodeIDs)):\n",
    "            # current payoff initialization\n",
    "            curr_payoff = 0\n",
    "            # possible payoff/list of payoffs initialize for every node\n",
    "            pp = 0\n",
    "            pps = []\n",
    "\n",
    "            # CURRENT payoff\n",
    "            for neighbor in xrange(len(grd.node[inode]['neighbors'])):\n",
    "                if grd.node[grd.node[inode]['neighbors'][neighbor]]['current_play'] == grd.node[inode]['current_play']:\n",
    "                    curr_payoff += 1\n",
    "\n",
    "            # POSSIBLE payoff\n",
    "            for strategy in xrange(len(grd.node[inode]['plays'])):\n",
    "                grd.node[inode]['possible_play'] = grd.node[inode]['plays'][strategy]\n",
    "                for neighbor in xrange(len(grd.node[inode]['neighbors'])):\n",
    "                    if grd.node[grd.node[inode]['neighbors'][neighbor]]['current_play'] == grd.node[inode]['possible_play']:\n",
    "                         pp += 1\n",
    "                pps.append(pp)\n",
    "                pp = 0\n",
    "\n",
    "            # Find strategy giving best payoff and update 'current_play' according to it\n",
    "            if np.max(pps) > curr_payoff:\n",
    "                # randomize strategy if max payoffs repeat\n",
    "                max_payoff_indices = [i for i, x in enumerate(pps) if x == max(pps)]\n",
    "                random_index = random.choice(max_payoff_indices)\n",
    "                # assign new strategy\n",
    "                grd.node[inode]['current_play'] = grd.node[inode]['plays'][random_index]\n",
    "                new_strategies[inode] = grd.node[inode]['current_play']\n",
    "\n",
    "    ### CALCULATE SOCIAL WELFARE ###\n",
    "\n",
    "\n",
    "    # initialize list with all players' payoffs\n",
    "    ind_payoffs = []\n",
    "    for inode in xrange(len(nodeIDs)):\n",
    "        ind_payoff = 0\n",
    "        for neighbor in xrange(len(grd.node[inode]['neighbors'])):\n",
    "            if grd.node[grd.node[inode]['neighbors'][neighbor]]['current_play'] == grd.node[inode]['current_play']:\n",
    "                ind_payoff += 1\n",
    "        ind_payoffs.append(ind_payoff)\n",
    "\n",
    "    social_welfare = sum(ind_payoffs)\n",
    "\n",
    "    ### OPTIMAL WELFARE APPROXIMATION ###\n",
    "\n",
    "    source_neighborhoods = []\n",
    "\n",
    "    # choose source with biggest ego_network\n",
    "    for source in xrange(len(k)):\n",
    "        source_neighborhoods.append(len(nx.ego_graph(gego, k[source], 2).nodes()))\n",
    "\n",
    "    for node in xrange(len(nodeIDs)):\n",
    "        gego.node[node][\"neighbors\"] = gdc[node]\n",
    "        if node in nx.ego_graph(gego, np.max(source_neighborhoods), 2).nodes():\n",
    "            # every node in ego graph gets only one strategy (source's strategy)\n",
    "            gego.node[node][\"current_play\"] = k[np.argmax(source_neighborhoods)]\n",
    "            gego.node[node][\"possible_play\"] = k[np.argmax(source_neighborhoods)]\n",
    "            gego.node[node][\"plays\"] = [k[np.argmax(source_neighborhoods)]]\n",
    "        elif node not in nx.ego_graph(gego, np.max(source_neighborhoods), 2).nodes():\n",
    "        #    # prepare for best response\n",
    "            gego.node[node][\"current_play\"] = node\n",
    "            gego.node[node][\"possible_play\"] = node\n",
    "\n",
    "    opt_past_strategies = [] # Initialize two lists to compare \n",
    "    opt_new_strategies = []\n",
    "    for i in xrange(len(nodeIDs)):\n",
    "        opt_new_strategies.append(gego.node[i]['current_play'])\n",
    "        opt_past_strategies.append(0)\n",
    "\n",
    "\n",
    "    ### While loop to find best strategies ###\n",
    "\n",
    "\n",
    "    while opt_past_strategies != opt_new_strategies:\n",
    "        opt_past_strategies = copy.copy(opt_new_strategies)\n",
    "        for inode in xrange(len(nodeIDs)):\n",
    "            # current payoff initialization\n",
    "            curr_payoff = 0\n",
    "            # possible payoff/list of payoffs initialize for every node\n",
    "            pp = 0\n",
    "            pps = []\n",
    "\n",
    "            # CURRENT payoff\n",
    "            for neighbor in xrange(len(gego.node[inode]['neighbors'])):\n",
    "                if gego.node[gego.node[inode]['neighbors'][neighbor]]['current_play'] == gego.node[inode]['current_play']:\n",
    "                    curr_payoff += 1\n",
    "\n",
    "            # POSSIBLE payoff\n",
    "            for strategy in xrange(len(gego.node[inode]['plays'])):\n",
    "                gego.node[inode]['possible_play'] = gego.node[inode]['plays'][strategy]\n",
    "                for neighbor in xrange(len(gego.node[inode]['neighbors'])):\n",
    "                    if gego.node[gego.node[inode]['neighbors'][neighbor]]['current_play'] == gego.node[inode]['possible_play']:\n",
    "                         pp += 1\n",
    "                pps.append(pp)\n",
    "                pp = 0\n",
    "\n",
    "            # Find strategy giving best payoff and update 'current_play' according to it\n",
    "            if np.max(pps) > curr_payoff:\n",
    "                # randomize strategy if max payoffs repeat\n",
    "                max_payoff_indices = [i for i, x in enumerate(pps) if x == max(pps)]\n",
    "                random_index = random.choice(max_payoff_indices)\n",
    "                # assign new strategy\n",
    "                gego.node[inode]['current_play'] = gego.node[inode]['plays'][random_index]\n",
    "                opt_new_strategies[inode] = gego.node[inode]['current_play']\n",
    "\n",
    "    ### CALCULATE SOCIAL WELFARE ###\n",
    "\n",
    "\n",
    "    # initialize list with all players' payoffs\n",
    "    opt_ind_payoffs = []\n",
    "    for inode in xrange(len(nodeIDs)):\n",
    "        opt_ind_payoff = 0\n",
    "        for neighbor in xrange(len(gego.node[inode]['neighbors'])):\n",
    "            if gego.node[gego.node[inode]['neighbors'][neighbor]]['current_play'] == gego.node[inode]['current_play']:\n",
    "                opt_ind_payoff += 1\n",
    "        opt_ind_payoffs.append(opt_ind_payoff)\n",
    "\n",
    "    opt_social_welfare = sum(opt_ind_payoffs)\n",
    "\n",
    "    if float(social_welfare) != 0:\n",
    "        PoA = float(opt_social_welfare) / float(social_welfare)\n",
    "    elif float(social_welfare) == 0:\n",
    "        PoA = float('inf')\n",
    "\n",
    "    ### 3\n",
    "    # add data to dataframe k | k size | PoA\n",
    "    df2 = pd.DataFrame([[k, len(k), social_welfare, opt_social_welfare, PoA ]], columns=('k', 'k size', 'SW', 'reasonable SW', 'PoA'))\n",
    "    frames = [data, df2]\n",
    "    data = pd.concat(frames)\n",
    "data.to_csv('FB4-random-k%s.csv' %str(len(k)), encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# |K|=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### EXPERIMENT K size = 5\n",
    "\n",
    "sizes = [1,3,4,5,6,7,8,9,10]\n",
    "# for j in xrange(len(sizes)): #for different sizes of k\n",
    "    # initialize dataframe k | k size | PoA\n",
    "data = pd.DataFrame(columns=('k', 'k size', 'PoA'))\n",
    "    ### 1\n",
    "\n",
    "    #random K set\n",
    "    #k = random.sample(xrange(len(nodeIDs)), sizes[j])\n",
    "\n",
    "for i in xrange(200):\n",
    "    ### 1\n",
    "\n",
    "    #random K set\n",
    "    k = random.sample(xrange(len(nodeIDs)), sizes[3])\n",
    "\n",
    "    ### 2\n",
    "\n",
    "    #ADD ALL CALCULATIONS FOR THIS k\n",
    "    grd = grdict.copy()\n",
    "    gdc = copy.copy(grd)\n",
    "    # make dictionary into graph\n",
    "    grd = nx.to_networkx_graph(grd)\n",
    "\n",
    "    ############## START STRATEGY DISTRIBUTION ###########\n",
    "\n",
    "    ### Initialize Identity matrix - everyone has their own strategy\n",
    "\n",
    "    strategies = np.identity(len(nodeIDs))\n",
    "\n",
    "    ### Make a copy of real graph to find strategy distribution (because we'll need to delete some edges)\n",
    "\n",
    "    H = grd.copy()\n",
    "\n",
    "    ### For strategy distribution disregard edges between nodes in k\n",
    "\n",
    "    #all possible edge combinations between the k_nodes\n",
    "    knode_pedges=list(itertools.combinations(k, 2))\n",
    "\n",
    "    #Identify if the nodes have edges among each other and store them\n",
    "    edges_between_k=[]\n",
    "    for pedge in knode_pedges:\n",
    "        for edge in H.edges():\n",
    "            if set(pedge)==set(edge):\n",
    "                edges_between_k.append(pedge)\n",
    "\n",
    "    # For the strategy distribution delete the edges between k in a duplicate H of our real graph grd! \n",
    "    H.remove_edges_from(edges_between_k)\n",
    "\n",
    "    ### Find neighborhood of range = 2 for nodes in k and assign them the strategy of that node\n",
    "\n",
    "    #Check how many nodes have neighborhood of 2 less than a 100\n",
    "\n",
    "    for i in xrange(len(k)):\n",
    "        for j in nx.ego_graph(H, k[i], 2).nodes():\n",
    "            if j not in k:\n",
    "                strategies[j][k[i]]=1\n",
    "\n",
    "    np.where(strategies[4] == 1)[0].tolist()\n",
    "\n",
    "    ### STRATEGY ASSIGNMENT TO NODES\n",
    "\n",
    "    #to avoid confusion attribute will be called plays rather than strategies (to separate from strategy matrix)\n",
    "\n",
    "    for i in xrange(len(nodeIDs)):\n",
    "        key=\"plays\"\n",
    "        #step of assigining attributes\n",
    "        grd.node[i].setdefault(key, np.where(strategies[i] == 1)[0].tolist()) \n",
    "\n",
    "    gego = grd.copy() # duplicate graph for 'OPTIMAL' calculations later\n",
    "\n",
    "    ### Create ATTRIBUTES in graph: neighbors, current_play, possible_play (to find what is my payoff \n",
    "    #                                                                       if I play this strategy)\n",
    "\n",
    "    for i in xrange(len(nodeIDs)):\n",
    "        # step of assigining attributes\n",
    "        grd.node[i].setdefault(\"neighbors\", gdc[i])\n",
    "        # everybody starts at their own strategy; 'possible_play' attribute for strategy update\n",
    "        grd.node[i].setdefault(\"current_play\", i)\n",
    "        grd.node[i].setdefault(\"possible_play\", i)\n",
    "\n",
    "    ### UPDATE STRATEGIES ### \n",
    "\n",
    "    # the idea is to have two strategy lists that will be compared after every iteration through all the nodes\n",
    "    # when the lists are identical, no player will switch strategies -> hence, Nash equilibrium\n",
    "\n",
    "\n",
    "    # Initialize two lists to compare \n",
    "    past_strategies = []\n",
    "    new_strategies = []\n",
    "    for i in xrange(len(nodeIDs)):\n",
    "        new_strategies.append(grd.node[i]['current_play'])\n",
    "        past_strategies.append(0)\n",
    "\n",
    "\n",
    "    ### WHILE LOOP TO FIND BEST STRATEGIES ###\n",
    "\n",
    "\n",
    "    i = 0\n",
    "    while past_strategies != new_strategies:\n",
    "        past_strategies = copy.copy(new_strategies)\n",
    "        for inode in xrange(len(nodeIDs)):\n",
    "            # current payoff initialization\n",
    "            curr_payoff = 0\n",
    "            # possible payoff/list of payoffs initialize for every node\n",
    "            pp = 0\n",
    "            pps = []\n",
    "\n",
    "            # CURRENT payoff\n",
    "            for neighbor in xrange(len(grd.node[inode]['neighbors'])):\n",
    "                if grd.node[grd.node[inode]['neighbors'][neighbor]]['current_play'] == grd.node[inode]['current_play']:\n",
    "                    curr_payoff += 1\n",
    "\n",
    "            # POSSIBLE payoff\n",
    "            for strategy in xrange(len(grd.node[inode]['plays'])):\n",
    "                grd.node[inode]['possible_play'] = grd.node[inode]['plays'][strategy]\n",
    "                for neighbor in xrange(len(grd.node[inode]['neighbors'])):\n",
    "                    if grd.node[grd.node[inode]['neighbors'][neighbor]]['current_play'] == grd.node[inode]['possible_play']:\n",
    "                         pp += 1\n",
    "                pps.append(pp)\n",
    "                pp = 0\n",
    "\n",
    "            # Find strategy giving best payoff and update 'current_play' according to it\n",
    "            if np.max(pps) > curr_payoff:\n",
    "                # randomize strategy if max payoffs repeat\n",
    "                max_payoff_indices = [i for i, x in enumerate(pps) if x == max(pps)]\n",
    "                random_index = random.choice(max_payoff_indices)\n",
    "                # assign new strategy\n",
    "                grd.node[inode]['current_play'] = grd.node[inode]['plays'][random_index]\n",
    "                new_strategies[inode] = grd.node[inode]['current_play']\n",
    "\n",
    "    ### CALCULATE SOCIAL WELFARE ###\n",
    "\n",
    "\n",
    "    # initialize list with all players' payoffs\n",
    "    ind_payoffs = []\n",
    "    for inode in xrange(len(nodeIDs)):\n",
    "        ind_payoff = 0\n",
    "        for neighbor in xrange(len(grd.node[inode]['neighbors'])):\n",
    "            if grd.node[grd.node[inode]['neighbors'][neighbor]]['current_play'] == grd.node[inode]['current_play']:\n",
    "                ind_payoff += 1\n",
    "        ind_payoffs.append(ind_payoff)\n",
    "\n",
    "    social_welfare = sum(ind_payoffs)\n",
    "\n",
    "    ### OPTIMAL WELFARE APPROXIMATION ###\n",
    "\n",
    "    source_neighborhoods = []\n",
    "\n",
    "    # choose source with biggest ego_network\n",
    "    for source in xrange(len(k)):\n",
    "        source_neighborhoods.append(len(nx.ego_graph(gego, k[source], 2).nodes()))\n",
    "\n",
    "    for node in xrange(len(nodeIDs)):\n",
    "        gego.node[node][\"neighbors\"] = gdc[node]\n",
    "        if node in nx.ego_graph(gego, np.max(source_neighborhoods), 2).nodes():\n",
    "            # every node in ego graph gets only one strategy (source's strategy)\n",
    "            gego.node[node][\"current_play\"] = k[np.argmax(source_neighborhoods)]\n",
    "            gego.node[node][\"possible_play\"] = k[np.argmax(source_neighborhoods)]\n",
    "            gego.node[node][\"plays\"] = [k[np.argmax(source_neighborhoods)]]\n",
    "        elif node not in nx.ego_graph(gego, np.max(source_neighborhoods), 2).nodes():\n",
    "        #    # prepare for best response\n",
    "            gego.node[node][\"current_play\"] = node\n",
    "            gego.node[node][\"possible_play\"] = node\n",
    "\n",
    "    opt_past_strategies = [] # Initialize two lists to compare \n",
    "    opt_new_strategies = []\n",
    "    for i in xrange(len(nodeIDs)):\n",
    "        opt_new_strategies.append(gego.node[i]['current_play'])\n",
    "        opt_past_strategies.append(0)\n",
    "\n",
    "\n",
    "    ### While loop to find best strategies ###\n",
    "\n",
    "\n",
    "    while opt_past_strategies != opt_new_strategies:\n",
    "        opt_past_strategies = copy.copy(opt_new_strategies)\n",
    "        for inode in xrange(len(nodeIDs)):\n",
    "            # current payoff initialization\n",
    "            curr_payoff = 0\n",
    "            # possible payoff/list of payoffs initialize for every node\n",
    "            pp = 0\n",
    "            pps = []\n",
    "\n",
    "            # CURRENT payoff\n",
    "            for neighbor in xrange(len(gego.node[inode]['neighbors'])):\n",
    "                if gego.node[gego.node[inode]['neighbors'][neighbor]]['current_play'] == gego.node[inode]['current_play']:\n",
    "                    curr_payoff += 1\n",
    "\n",
    "            # POSSIBLE payoff\n",
    "            for strategy in xrange(len(gego.node[inode]['plays'])):\n",
    "                gego.node[inode]['possible_play'] = gego.node[inode]['plays'][strategy]\n",
    "                for neighbor in xrange(len(gego.node[inode]['neighbors'])):\n",
    "                    if gego.node[gego.node[inode]['neighbors'][neighbor]]['current_play'] == gego.node[inode]['possible_play']:\n",
    "                         pp += 1\n",
    "                pps.append(pp)\n",
    "                pp = 0\n",
    "\n",
    "            # Find strategy giving best payoff and update 'current_play' according to it\n",
    "            if np.max(pps) > curr_payoff:\n",
    "                # randomize strategy if max payoffs repeat\n",
    "                max_payoff_indices = [i for i, x in enumerate(pps) if x == max(pps)]\n",
    "                random_index = random.choice(max_payoff_indices)\n",
    "                # assign new strategy\n",
    "                gego.node[inode]['current_play'] = gego.node[inode]['plays'][random_index]\n",
    "                opt_new_strategies[inode] = gego.node[inode]['current_play']\n",
    "\n",
    "    ### CALCULATE SOCIAL WELFARE ###\n",
    "\n",
    "\n",
    "    # initialize list with all players' payoffs\n",
    "    opt_ind_payoffs = []\n",
    "    for inode in xrange(len(nodeIDs)):\n",
    "        opt_ind_payoff = 0\n",
    "        for neighbor in xrange(len(gego.node[inode]['neighbors'])):\n",
    "            if gego.node[gego.node[inode]['neighbors'][neighbor]]['current_play'] == gego.node[inode]['current_play']:\n",
    "                opt_ind_payoff += 1\n",
    "        opt_ind_payoffs.append(opt_ind_payoff)\n",
    "\n",
    "    opt_social_welfare = sum(opt_ind_payoffs)\n",
    "\n",
    "    if float(social_welfare) != 0:\n",
    "        PoA = float(opt_social_welfare) / float(social_welfare)\n",
    "    elif float(social_welfare) == 0:\n",
    "        PoA = float('inf')\n",
    "\n",
    "    ### 3\n",
    "    # add data to dataframe k | k size | PoA\n",
    "    df2 = pd.DataFrame([[k, len(k), social_welfare, opt_social_welfare, PoA ]], columns=('k', 'k size', 'SW', 'reasonable SW', 'PoA'))\n",
    "    frames = [data, df2]\n",
    "    data = pd.concat(frames)\n",
    "data.to_csv('FB4-random-k%s.csv' %str(len(k)), encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# |K|=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### EXPERIMENT K size = 6\n",
    "\n",
    "sizes = [1,3,4,5,6,7,8,9,10]\n",
    "# for j in xrange(len(sizes)): #for different sizes of k\n",
    "    # initialize dataframe k | k size | PoA\n",
    "data = pd.DataFrame(columns=('k', 'k size', 'PoA'))\n",
    "    ### 1\n",
    "\n",
    "    #random K set\n",
    "    #k = random.sample(xrange(len(nodeIDs)), sizes[j])\n",
    "\n",
    "for i in xrange(200):\n",
    "    ### 1\n",
    "\n",
    "    #random K set\n",
    "    k = random.sample(xrange(len(nodeIDs)), sizes[4])\n",
    "\n",
    "    ### 2\n",
    "\n",
    "    #ADD ALL CALCULATIONS FOR THIS k\n",
    "    grd = grdict.copy()\n",
    "    gdc = copy.copy(grd)\n",
    "    # make dictionary into graph\n",
    "    grd = nx.to_networkx_graph(grd)\n",
    "\n",
    "    ############## START STRATEGY DISTRIBUTION ###########\n",
    "\n",
    "    ### Initialize Identity matrix - everyone has their own strategy\n",
    "\n",
    "    strategies = np.identity(len(nodeIDs))\n",
    "\n",
    "    ### Make a copy of real graph to find strategy distribution (because we'll need to delete some edges)\n",
    "\n",
    "    H = grd.copy()\n",
    "\n",
    "    ### For strategy distribution disregard edges between nodes in k\n",
    "\n",
    "    #all possible edge combinations between the k_nodes\n",
    "    knode_pedges=list(itertools.combinations(k, 2))\n",
    "\n",
    "    #Identify if the nodes have edges among each other and store them\n",
    "    edges_between_k=[]\n",
    "    for pedge in knode_pedges:\n",
    "        for edge in H.edges():\n",
    "            if set(pedge)==set(edge):\n",
    "                edges_between_k.append(pedge)\n",
    "\n",
    "    # For the strategy distribution delete the edges between k in a duplicate H of our real graph grd! \n",
    "    H.remove_edges_from(edges_between_k)\n",
    "\n",
    "    ### Find neighborhood of range = 2 for nodes in k and assign them the strategy of that node\n",
    "\n",
    "    #Check how many nodes have neighborhood of 2 less than a 100\n",
    "\n",
    "    for i in xrange(len(k)):\n",
    "        for j in nx.ego_graph(H, k[i], 2).nodes():\n",
    "            if j not in k:\n",
    "                strategies[j][k[i]]=1\n",
    "\n",
    "    np.where(strategies[4] == 1)[0].tolist()\n",
    "\n",
    "    ### STRATEGY ASSIGNMENT TO NODES\n",
    "\n",
    "    #to avoid confusion attribute will be called plays rather than strategies (to separate from strategy matrix)\n",
    "\n",
    "    for i in xrange(len(nodeIDs)):\n",
    "        key=\"plays\"\n",
    "        #step of assigining attributes\n",
    "        grd.node[i].setdefault(key, np.where(strategies[i] == 1)[0].tolist()) \n",
    "\n",
    "    gego = grd.copy() # duplicate graph for 'OPTIMAL' calculations later\n",
    "\n",
    "    ### Create ATTRIBUTES in graph: neighbors, current_play, possible_play (to find what is my payoff \n",
    "    #                                                                       if I play this strategy)\n",
    "\n",
    "    for i in xrange(len(nodeIDs)):\n",
    "        # step of assigining attributes\n",
    "        grd.node[i].setdefault(\"neighbors\", gdc[i])\n",
    "        # everybody starts at their own strategy; 'possible_play' attribute for strategy update\n",
    "        grd.node[i].setdefault(\"current_play\", i)\n",
    "        grd.node[i].setdefault(\"possible_play\", i)\n",
    "\n",
    "    ### UPDATE STRATEGIES ### \n",
    "\n",
    "    # the idea is to have two strategy lists that will be compared after every iteration through all the nodes\n",
    "    # when the lists are identical, no player will switch strategies -> hence, Nash equilibrium\n",
    "\n",
    "\n",
    "    # Initialize two lists to compare \n",
    "    past_strategies = []\n",
    "    new_strategies = []\n",
    "    for i in xrange(len(nodeIDs)):\n",
    "        new_strategies.append(grd.node[i]['current_play'])\n",
    "        past_strategies.append(0)\n",
    "\n",
    "\n",
    "    ### WHILE LOOP TO FIND BEST STRATEGIES ###\n",
    "\n",
    "\n",
    "    i = 0\n",
    "    while past_strategies != new_strategies:\n",
    "        past_strategies = copy.copy(new_strategies)\n",
    "        for inode in xrange(len(nodeIDs)):\n",
    "            # current payoff initialization\n",
    "            curr_payoff = 0\n",
    "            # possible payoff/list of payoffs initialize for every node\n",
    "            pp = 0\n",
    "            pps = []\n",
    "\n",
    "            # CURRENT payoff\n",
    "            for neighbor in xrange(len(grd.node[inode]['neighbors'])):\n",
    "                if grd.node[grd.node[inode]['neighbors'][neighbor]]['current_play'] == grd.node[inode]['current_play']:\n",
    "                    curr_payoff += 1\n",
    "\n",
    "            # POSSIBLE payoff\n",
    "            for strategy in xrange(len(grd.node[inode]['plays'])):\n",
    "                grd.node[inode]['possible_play'] = grd.node[inode]['plays'][strategy]\n",
    "                for neighbor in xrange(len(grd.node[inode]['neighbors'])):\n",
    "                    if grd.node[grd.node[inode]['neighbors'][neighbor]]['current_play'] == grd.node[inode]['possible_play']:\n",
    "                         pp += 1\n",
    "                pps.append(pp)\n",
    "                pp = 0\n",
    "\n",
    "            # Find strategy giving best payoff and update 'current_play' according to it\n",
    "            if np.max(pps) > curr_payoff:\n",
    "                # randomize strategy if max payoffs repeat\n",
    "                max_payoff_indices = [i for i, x in enumerate(pps) if x == max(pps)]\n",
    "                random_index = random.choice(max_payoff_indices)\n",
    "                # assign new strategy\n",
    "                grd.node[inode]['current_play'] = grd.node[inode]['plays'][random_index]\n",
    "                new_strategies[inode] = grd.node[inode]['current_play']\n",
    "\n",
    "    ### CALCULATE SOCIAL WELFARE ###\n",
    "\n",
    "\n",
    "    # initialize list with all players' payoffs\n",
    "    ind_payoffs = []\n",
    "    for inode in xrange(len(nodeIDs)):\n",
    "        ind_payoff = 0\n",
    "        for neighbor in xrange(len(grd.node[inode]['neighbors'])):\n",
    "            if grd.node[grd.node[inode]['neighbors'][neighbor]]['current_play'] == grd.node[inode]['current_play']:\n",
    "                ind_payoff += 1\n",
    "        ind_payoffs.append(ind_payoff)\n",
    "\n",
    "    social_welfare = sum(ind_payoffs)\n",
    "\n",
    "    ### OPTIMAL WELFARE APPROXIMATION ###\n",
    "\n",
    "    source_neighborhoods = []\n",
    "\n",
    "    # choose source with biggest ego_network\n",
    "    for source in xrange(len(k)):\n",
    "        source_neighborhoods.append(len(nx.ego_graph(gego, k[source], 2).nodes()))\n",
    "\n",
    "    for node in xrange(len(nodeIDs)):\n",
    "        gego.node[node][\"neighbors\"] = gdc[node]\n",
    "        if node in nx.ego_graph(gego, np.max(source_neighborhoods), 2).nodes():\n",
    "            # every node in ego graph gets only one strategy (source's strategy)\n",
    "            gego.node[node][\"current_play\"] = k[np.argmax(source_neighborhoods)]\n",
    "            gego.node[node][\"possible_play\"] = k[np.argmax(source_neighborhoods)]\n",
    "            gego.node[node][\"plays\"] = [k[np.argmax(source_neighborhoods)]]\n",
    "        elif node not in nx.ego_graph(gego, np.max(source_neighborhoods), 2).nodes():\n",
    "        #    # prepare for best response\n",
    "            gego.node[node][\"current_play\"] = node\n",
    "            gego.node[node][\"possible_play\"] = node\n",
    "\n",
    "    opt_past_strategies = [] # Initialize two lists to compare \n",
    "    opt_new_strategies = []\n",
    "    for i in xrange(len(nodeIDs)):\n",
    "        opt_new_strategies.append(gego.node[i]['current_play'])\n",
    "        opt_past_strategies.append(0)\n",
    "\n",
    "\n",
    "    ### While loop to find best strategies ###\n",
    "\n",
    "\n",
    "    while opt_past_strategies != opt_new_strategies:\n",
    "        opt_past_strategies = copy.copy(opt_new_strategies)\n",
    "        for inode in xrange(len(nodeIDs)):\n",
    "            # current payoff initialization\n",
    "            curr_payoff = 0\n",
    "            # possible payoff/list of payoffs initialize for every node\n",
    "            pp = 0\n",
    "            pps = []\n",
    "\n",
    "            # CURRENT payoff\n",
    "            for neighbor in xrange(len(gego.node[inode]['neighbors'])):\n",
    "                if gego.node[gego.node[inode]['neighbors'][neighbor]]['current_play'] == gego.node[inode]['current_play']:\n",
    "                    curr_payoff += 1\n",
    "\n",
    "            # POSSIBLE payoff\n",
    "            for strategy in xrange(len(gego.node[inode]['plays'])):\n",
    "                gego.node[inode]['possible_play'] = gego.node[inode]['plays'][strategy]\n",
    "                for neighbor in xrange(len(gego.node[inode]['neighbors'])):\n",
    "                    if gego.node[gego.node[inode]['neighbors'][neighbor]]['current_play'] == gego.node[inode]['possible_play']:\n",
    "                         pp += 1\n",
    "                pps.append(pp)\n",
    "                pp = 0\n",
    "\n",
    "            # Find strategy giving best payoff and update 'current_play' according to it\n",
    "            if np.max(pps) > curr_payoff:\n",
    "                # randomize strategy if max payoffs repeat\n",
    "                max_payoff_indices = [i for i, x in enumerate(pps) if x == max(pps)]\n",
    "                random_index = random.choice(max_payoff_indices)\n",
    "                # assign new strategy\n",
    "                gego.node[inode]['current_play'] = gego.node[inode]['plays'][random_index]\n",
    "                opt_new_strategies[inode] = gego.node[inode]['current_play']\n",
    "\n",
    "    ### CALCULATE SOCIAL WELFARE ###\n",
    "\n",
    "\n",
    "    # initialize list with all players' payoffs\n",
    "    opt_ind_payoffs = []\n",
    "    for inode in xrange(len(nodeIDs)):\n",
    "        opt_ind_payoff = 0\n",
    "        for neighbor in xrange(len(gego.node[inode]['neighbors'])):\n",
    "            if gego.node[gego.node[inode]['neighbors'][neighbor]]['current_play'] == gego.node[inode]['current_play']:\n",
    "                opt_ind_payoff += 1\n",
    "        opt_ind_payoffs.append(opt_ind_payoff)\n",
    "\n",
    "    opt_social_welfare = sum(opt_ind_payoffs)\n",
    "\n",
    "    if float(social_welfare) != 0:\n",
    "        PoA = float(opt_social_welfare) / float(social_welfare)\n",
    "    elif float(social_welfare) == 0:\n",
    "        PoA = float('inf')\n",
    "\n",
    "    ### 3\n",
    "    # add data to dataframe k | k size | PoA\n",
    "    df2 = pd.DataFrame([[k, len(k), social_welfare, opt_social_welfare, PoA ]], columns=('k', 'k size', 'SW', 'reasonable SW', 'PoA'))\n",
    "    frames = [data, df2]\n",
    "    data = pd.concat(frames)\n",
    "data.to_csv('FB4-random-k%s.csv' %str(len(k)), encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# |K| = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### EXPERIMENT K size = 7\n",
    "\n",
    "sizes = [1,3,4,5,6,7,8,9,10]\n",
    "# for j in xrange(len(sizes)): #for different sizes of k\n",
    "    # initialize dataframe k | k size | PoA\n",
    "data = pd.DataFrame(columns=('k', 'k size', 'PoA'))\n",
    "    ### 1\n",
    "\n",
    "    #random K set\n",
    "    #k = random.sample(xrange(len(nodeIDs)), sizes[j])\n",
    "\n",
    "for i in xrange(200):\n",
    "    ### 1\n",
    "\n",
    "    #random K set\n",
    "    k = random.sample(xrange(len(nodeIDs)), sizes[5])\n",
    "\n",
    "    ### 2\n",
    "\n",
    "    #ADD ALL CALCULATIONS FOR THIS k\n",
    "    grd = grdict.copy()\n",
    "    gdc = copy.copy(grd)\n",
    "    # make dictionary into graph\n",
    "    grd = nx.to_networkx_graph(grd)\n",
    "\n",
    "    ############## START STRATEGY DISTRIBUTION ###########\n",
    "\n",
    "    ### Initialize Identity matrix - everyone has their own strategy\n",
    "\n",
    "    strategies = np.identity(len(nodeIDs))\n",
    "\n",
    "    ### Make a copy of real graph to find strategy distribution (because we'll need to delete some edges)\n",
    "\n",
    "    H = grd.copy()\n",
    "\n",
    "    ### For strategy distribution disregard edges between nodes in k\n",
    "\n",
    "    #all possible edge combinations between the k_nodes\n",
    "    knode_pedges=list(itertools.combinations(k, 2))\n",
    "\n",
    "    #Identify if the nodes have edges among each other and store them\n",
    "    edges_between_k=[]\n",
    "    for pedge in knode_pedges:\n",
    "        for edge in H.edges():\n",
    "            if set(pedge)==set(edge):\n",
    "                edges_between_k.append(pedge)\n",
    "\n",
    "    # For the strategy distribution delete the edges between k in a duplicate H of our real graph grd! \n",
    "    H.remove_edges_from(edges_between_k)\n",
    "\n",
    "    ### Find neighborhood of range = 2 for nodes in k and assign them the strategy of that node\n",
    "\n",
    "    #Check how many nodes have neighborhood of 2 less than a 100\n",
    "\n",
    "    for i in xrange(len(k)):\n",
    "        for j in nx.ego_graph(H, k[i], 2).nodes():\n",
    "            if j not in k:\n",
    "                strategies[j][k[i]]=1\n",
    "\n",
    "    np.where(strategies[4] == 1)[0].tolist()\n",
    "\n",
    "    ### STRATEGY ASSIGNMENT TO NODES\n",
    "\n",
    "    #to avoid confusion attribute will be called plays rather than strategies (to separate from strategy matrix)\n",
    "\n",
    "    for i in xrange(len(nodeIDs)):\n",
    "        key=\"plays\"\n",
    "        #step of assigining attributes\n",
    "        grd.node[i].setdefault(key, np.where(strategies[i] == 1)[0].tolist()) \n",
    "\n",
    "    gego = grd.copy() # duplicate graph for 'OPTIMAL' calculations later\n",
    "\n",
    "    ### Create ATTRIBUTES in graph: neighbors, current_play, possible_play (to find what is my payoff \n",
    "    #                                                                       if I play this strategy)\n",
    "\n",
    "    for i in xrange(len(nodeIDs)):\n",
    "        # step of assigining attributes\n",
    "        grd.node[i].setdefault(\"neighbors\", gdc[i])\n",
    "        # everybody starts at their own strategy; 'possible_play' attribute for strategy update\n",
    "        grd.node[i].setdefault(\"current_play\", i)\n",
    "        grd.node[i].setdefault(\"possible_play\", i)\n",
    "\n",
    "    ### UPDATE STRATEGIES ### \n",
    "\n",
    "    # the idea is to have two strategy lists that will be compared after every iteration through all the nodes\n",
    "    # when the lists are identical, no player will switch strategies -> hence, Nash equilibrium\n",
    "\n",
    "\n",
    "    # Initialize two lists to compare \n",
    "    past_strategies = []\n",
    "    new_strategies = []\n",
    "    for i in xrange(len(nodeIDs)):\n",
    "        new_strategies.append(grd.node[i]['current_play'])\n",
    "        past_strategies.append(0)\n",
    "\n",
    "\n",
    "    ### WHILE LOOP TO FIND BEST STRATEGIES ###\n",
    "\n",
    "\n",
    "    i = 0\n",
    "    while past_strategies != new_strategies:\n",
    "        past_strategies = copy.copy(new_strategies)\n",
    "        for inode in xrange(len(nodeIDs)):\n",
    "            # current payoff initialization\n",
    "            curr_payoff = 0\n",
    "            # possible payoff/list of payoffs initialize for every node\n",
    "            pp = 0\n",
    "            pps = []\n",
    "\n",
    "            # CURRENT payoff\n",
    "            for neighbor in xrange(len(grd.node[inode]['neighbors'])):\n",
    "                if grd.node[grd.node[inode]['neighbors'][neighbor]]['current_play'] == grd.node[inode]['current_play']:\n",
    "                    curr_payoff += 1\n",
    "\n",
    "            # POSSIBLE payoff\n",
    "            for strategy in xrange(len(grd.node[inode]['plays'])):\n",
    "                grd.node[inode]['possible_play'] = grd.node[inode]['plays'][strategy]\n",
    "                for neighbor in xrange(len(grd.node[inode]['neighbors'])):\n",
    "                    if grd.node[grd.node[inode]['neighbors'][neighbor]]['current_play'] == grd.node[inode]['possible_play']:\n",
    "                         pp += 1\n",
    "                pps.append(pp)\n",
    "                pp = 0\n",
    "\n",
    "            # Find strategy giving best payoff and update 'current_play' according to it\n",
    "            if np.max(pps) > curr_payoff:\n",
    "                # randomize strategy if max payoffs repeat\n",
    "                max_payoff_indices = [i for i, x in enumerate(pps) if x == max(pps)]\n",
    "                random_index = random.choice(max_payoff_indices)\n",
    "                # assign new strategy\n",
    "                grd.node[inode]['current_play'] = grd.node[inode]['plays'][random_index]\n",
    "                new_strategies[inode] = grd.node[inode]['current_play']\n",
    "\n",
    "    ### CALCULATE SOCIAL WELFARE ###\n",
    "\n",
    "\n",
    "    # initialize list with all players' payoffs\n",
    "    ind_payoffs = []\n",
    "    for inode in xrange(len(nodeIDs)):\n",
    "        ind_payoff = 0\n",
    "        for neighbor in xrange(len(grd.node[inode]['neighbors'])):\n",
    "            if grd.node[grd.node[inode]['neighbors'][neighbor]]['current_play'] == grd.node[inode]['current_play']:\n",
    "                ind_payoff += 1\n",
    "        ind_payoffs.append(ind_payoff)\n",
    "\n",
    "    social_welfare = sum(ind_payoffs)\n",
    "\n",
    "    ### OPTIMAL WELFARE APPROXIMATION ###\n",
    "\n",
    "    source_neighborhoods = []\n",
    "\n",
    "    # choose source with biggest ego_network\n",
    "    for source in xrange(len(k)):\n",
    "        source_neighborhoods.append(len(nx.ego_graph(gego, k[source], 2).nodes()))\n",
    "\n",
    "    for node in xrange(len(nodeIDs)):\n",
    "        gego.node[node][\"neighbors\"] = gdc[node]\n",
    "        if node in nx.ego_graph(gego, np.max(source_neighborhoods), 2).nodes():\n",
    "            # every node in ego graph gets only one strategy (source's strategy)\n",
    "            gego.node[node][\"current_play\"] = k[np.argmax(source_neighborhoods)]\n",
    "            gego.node[node][\"possible_play\"] = k[np.argmax(source_neighborhoods)]\n",
    "            gego.node[node][\"plays\"] = [k[np.argmax(source_neighborhoods)]]\n",
    "        elif node not in nx.ego_graph(gego, np.max(source_neighborhoods), 2).nodes():\n",
    "        #    # prepare for best response\n",
    "            gego.node[node][\"current_play\"] = node\n",
    "            gego.node[node][\"possible_play\"] = node\n",
    "\n",
    "    opt_past_strategies = [] # Initialize two lists to compare \n",
    "    opt_new_strategies = []\n",
    "    for i in xrange(len(nodeIDs)):\n",
    "        opt_new_strategies.append(gego.node[i]['current_play'])\n",
    "        opt_past_strategies.append(0)\n",
    "\n",
    "\n",
    "    ### While loop to find best strategies ###\n",
    "\n",
    "\n",
    "    while opt_past_strategies != opt_new_strategies:\n",
    "        opt_past_strategies = copy.copy(opt_new_strategies)\n",
    "        for inode in xrange(len(nodeIDs)):\n",
    "            # current payoff initialization\n",
    "            curr_payoff = 0\n",
    "            # possible payoff/list of payoffs initialize for every node\n",
    "            pp = 0\n",
    "            pps = []\n",
    "\n",
    "            # CURRENT payoff\n",
    "            for neighbor in xrange(len(gego.node[inode]['neighbors'])):\n",
    "                if gego.node[gego.node[inode]['neighbors'][neighbor]]['current_play'] == gego.node[inode]['current_play']:\n",
    "                    curr_payoff += 1\n",
    "\n",
    "            # POSSIBLE payoff\n",
    "            for strategy in xrange(len(gego.node[inode]['plays'])):\n",
    "                gego.node[inode]['possible_play'] = gego.node[inode]['plays'][strategy]\n",
    "                for neighbor in xrange(len(gego.node[inode]['neighbors'])):\n",
    "                    if gego.node[gego.node[inode]['neighbors'][neighbor]]['current_play'] == gego.node[inode]['possible_play']:\n",
    "                         pp += 1\n",
    "                pps.append(pp)\n",
    "                pp = 0\n",
    "\n",
    "            # Find strategy giving best payoff and update 'current_play' according to it\n",
    "            if np.max(pps) > curr_payoff:\n",
    "                # randomize strategy if max payoffs repeat\n",
    "                max_payoff_indices = [i for i, x in enumerate(pps) if x == max(pps)]\n",
    "                random_index = random.choice(max_payoff_indices)\n",
    "                # assign new strategy\n",
    "                gego.node[inode]['current_play'] = gego.node[inode]['plays'][random_index]\n",
    "                opt_new_strategies[inode] = gego.node[inode]['current_play']\n",
    "\n",
    "    ### CALCULATE SOCIAL WELFARE ###\n",
    "\n",
    "\n",
    "    # initialize list with all players' payoffs\n",
    "    opt_ind_payoffs = []\n",
    "    for inode in xrange(len(nodeIDs)):\n",
    "        opt_ind_payoff = 0\n",
    "        for neighbor in xrange(len(gego.node[inode]['neighbors'])):\n",
    "            if gego.node[gego.node[inode]['neighbors'][neighbor]]['current_play'] == gego.node[inode]['current_play']:\n",
    "                opt_ind_payoff += 1\n",
    "        opt_ind_payoffs.append(opt_ind_payoff)\n",
    "\n",
    "    opt_social_welfare = sum(opt_ind_payoffs)\n",
    "\n",
    "    if float(social_welfare) != 0:\n",
    "        PoA = float(opt_social_welfare) / float(social_welfare)\n",
    "    elif float(social_welfare) == 0:\n",
    "        PoA = float('inf')\n",
    "\n",
    "    ### 3\n",
    "    # add data to dataframe k | k size | PoA\n",
    "    df2 = pd.DataFrame([[k, len(k), social_welfare, opt_social_welfare, PoA ]], columns=('k', 'k size', 'SW', 'reasonable SW', 'PoA'))\n",
    "    frames = [data, df2]\n",
    "    data = pd.concat(frames)\n",
    "data.to_csv('FB4-random-k%s.csv' %str(len(k)), encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# |K| = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### EXPERIMENT K size = 8\n",
    "\n",
    "sizes = [1,3,4,5,6,7,8,9,10]\n",
    "# for j in xrange(len(sizes)): #for different sizes of k\n",
    "    # initialize dataframe k | k size | PoA\n",
    "data = pd.DataFrame(columns=('k', 'k size', 'PoA'))\n",
    "    ### 1\n",
    "\n",
    "    #random K set\n",
    "    #k = random.sample(xrange(len(nodeIDs)), sizes[j])\n",
    "\n",
    "for i in xrange(200):\n",
    "    ### 1\n",
    "\n",
    "    #random K set\n",
    "    k = random.sample(xrange(len(nodeIDs)), sizes[6])\n",
    "\n",
    "    ### 2\n",
    "\n",
    "    #ADD ALL CALCULATIONS FOR THIS k\n",
    "    grd = grdict.copy()\n",
    "    gdc = copy.copy(grd)\n",
    "    # make dictionary into graph\n",
    "    grd = nx.to_networkx_graph(grd)\n",
    "\n",
    "    ############## START STRATEGY DISTRIBUTION ###########\n",
    "\n",
    "    ### Initialize Identity matrix - everyone has their own strategy\n",
    "\n",
    "    strategies = np.identity(len(nodeIDs))\n",
    "\n",
    "    ### Make a copy of real graph to find strategy distribution (because we'll need to delete some edges)\n",
    "\n",
    "    H = grd.copy()\n",
    "\n",
    "    ### For strategy distribution disregard edges between nodes in k\n",
    "\n",
    "    #all possible edge combinations between the k_nodes\n",
    "    knode_pedges=list(itertools.combinations(k, 2))\n",
    "\n",
    "    #Identify if the nodes have edges among each other and store them\n",
    "    edges_between_k=[]\n",
    "    for pedge in knode_pedges:\n",
    "        for edge in H.edges():\n",
    "            if set(pedge)==set(edge):\n",
    "                edges_between_k.append(pedge)\n",
    "\n",
    "    # For the strategy distribution delete the edges between k in a duplicate H of our real graph grd! \n",
    "    H.remove_edges_from(edges_between_k)\n",
    "\n",
    "    ### Find neighborhood of range = 2 for nodes in k and assign them the strategy of that node\n",
    "\n",
    "    #Check how many nodes have neighborhood of 2 less than a 100\n",
    "\n",
    "    for i in xrange(len(k)):\n",
    "        for j in nx.ego_graph(H, k[i], 2).nodes():\n",
    "            if j not in k:\n",
    "                strategies[j][k[i]]=1\n",
    "\n",
    "    np.where(strategies[4] == 1)[0].tolist()\n",
    "\n",
    "    ### STRATEGY ASSIGNMENT TO NODES\n",
    "\n",
    "    #to avoid confusion attribute will be called plays rather than strategies (to separate from strategy matrix)\n",
    "\n",
    "    for i in xrange(len(nodeIDs)):\n",
    "        key=\"plays\"\n",
    "        #step of assigining attributes\n",
    "        grd.node[i].setdefault(key, np.where(strategies[i] == 1)[0].tolist()) \n",
    "\n",
    "    gego = grd.copy() # duplicate graph for 'OPTIMAL' calculations later\n",
    "\n",
    "    ### Create ATTRIBUTES in graph: neighbors, current_play, possible_play (to find what is my payoff \n",
    "    #                                                                       if I play this strategy)\n",
    "\n",
    "    for i in xrange(len(nodeIDs)):\n",
    "        # step of assigining attributes\n",
    "        grd.node[i].setdefault(\"neighbors\", gdc[i])\n",
    "        # everybody starts at their own strategy; 'possible_play' attribute for strategy update\n",
    "        grd.node[i].setdefault(\"current_play\", i)\n",
    "        grd.node[i].setdefault(\"possible_play\", i)\n",
    "\n",
    "    ### UPDATE STRATEGIES ### \n",
    "\n",
    "    # the idea is to have two strategy lists that will be compared after every iteration through all the nodes\n",
    "    # when the lists are identical, no player will switch strategies -> hence, Nash equilibrium\n",
    "\n",
    "\n",
    "    # Initialize two lists to compare \n",
    "    past_strategies = []\n",
    "    new_strategies = []\n",
    "    for i in xrange(len(nodeIDs)):\n",
    "        new_strategies.append(grd.node[i]['current_play'])\n",
    "        past_strategies.append(0)\n",
    "\n",
    "\n",
    "    ### WHILE LOOP TO FIND BEST STRATEGIES ###\n",
    "\n",
    "\n",
    "    i = 0\n",
    "    while past_strategies != new_strategies:\n",
    "        past_strategies = copy.copy(new_strategies)\n",
    "        for inode in xrange(len(nodeIDs)):\n",
    "            # current payoff initialization\n",
    "            curr_payoff = 0\n",
    "            # possible payoff/list of payoffs initialize for every node\n",
    "            pp = 0\n",
    "            pps = []\n",
    "\n",
    "            # CURRENT payoff\n",
    "            for neighbor in xrange(len(grd.node[inode]['neighbors'])):\n",
    "                if grd.node[grd.node[inode]['neighbors'][neighbor]]['current_play'] == grd.node[inode]['current_play']:\n",
    "                    curr_payoff += 1\n",
    "\n",
    "            # POSSIBLE payoff\n",
    "            for strategy in xrange(len(grd.node[inode]['plays'])):\n",
    "                grd.node[inode]['possible_play'] = grd.node[inode]['plays'][strategy]\n",
    "                for neighbor in xrange(len(grd.node[inode]['neighbors'])):\n",
    "                    if grd.node[grd.node[inode]['neighbors'][neighbor]]['current_play'] == grd.node[inode]['possible_play']:\n",
    "                         pp += 1\n",
    "                pps.append(pp)\n",
    "                pp = 0\n",
    "\n",
    "            # Find strategy giving best payoff and update 'current_play' according to it\n",
    "            if np.max(pps) > curr_payoff:\n",
    "                # randomize strategy if max payoffs repeat\n",
    "                max_payoff_indices = [i for i, x in enumerate(pps) if x == max(pps)]\n",
    "                random_index = random.choice(max_payoff_indices)\n",
    "                # assign new strategy\n",
    "                grd.node[inode]['current_play'] = grd.node[inode]['plays'][random_index]\n",
    "                new_strategies[inode] = grd.node[inode]['current_play']\n",
    "\n",
    "    ### CALCULATE SOCIAL WELFARE ###\n",
    "\n",
    "\n",
    "    # initialize list with all players' payoffs\n",
    "    ind_payoffs = []\n",
    "    for inode in xrange(len(nodeIDs)):\n",
    "        ind_payoff = 0\n",
    "        for neighbor in xrange(len(grd.node[inode]['neighbors'])):\n",
    "            if grd.node[grd.node[inode]['neighbors'][neighbor]]['current_play'] == grd.node[inode]['current_play']:\n",
    "                ind_payoff += 1\n",
    "        ind_payoffs.append(ind_payoff)\n",
    "\n",
    "    social_welfare = sum(ind_payoffs)\n",
    "\n",
    "    ### OPTIMAL WELFARE APPROXIMATION ###\n",
    "\n",
    "    source_neighborhoods = []\n",
    "\n",
    "    # choose source with biggest ego_network\n",
    "    for source in xrange(len(k)):\n",
    "        source_neighborhoods.append(len(nx.ego_graph(gego, k[source], 2).nodes()))\n",
    "\n",
    "    for node in xrange(len(nodeIDs)):\n",
    "        gego.node[node][\"neighbors\"] = gdc[node]\n",
    "        if node in nx.ego_graph(gego, np.max(source_neighborhoods), 2).nodes():\n",
    "            # every node in ego graph gets only one strategy (source's strategy)\n",
    "            gego.node[node][\"current_play\"] = k[np.argmax(source_neighborhoods)]\n",
    "            gego.node[node][\"possible_play\"] = k[np.argmax(source_neighborhoods)]\n",
    "            gego.node[node][\"plays\"] = [k[np.argmax(source_neighborhoods)]]\n",
    "        elif node not in nx.ego_graph(gego, np.max(source_neighborhoods), 2).nodes():\n",
    "        #    # prepare for best response\n",
    "            gego.node[node][\"current_play\"] = node\n",
    "            gego.node[node][\"possible_play\"] = node\n",
    "\n",
    "    opt_past_strategies = [] # Initialize two lists to compare \n",
    "    opt_new_strategies = []\n",
    "    for i in xrange(len(nodeIDs)):\n",
    "        opt_new_strategies.append(gego.node[i]['current_play'])\n",
    "        opt_past_strategies.append(0)\n",
    "\n",
    "\n",
    "    ### While loop to find best strategies ###\n",
    "\n",
    "\n",
    "    while opt_past_strategies != opt_new_strategies:\n",
    "        opt_past_strategies = copy.copy(opt_new_strategies)\n",
    "        for inode in xrange(len(nodeIDs)):\n",
    "            # current payoff initialization\n",
    "            curr_payoff = 0\n",
    "            # possible payoff/list of payoffs initialize for every node\n",
    "            pp = 0\n",
    "            pps = []\n",
    "\n",
    "            # CURRENT payoff\n",
    "            for neighbor in xrange(len(gego.node[inode]['neighbors'])):\n",
    "                if gego.node[gego.node[inode]['neighbors'][neighbor]]['current_play'] == gego.node[inode]['current_play']:\n",
    "                    curr_payoff += 1\n",
    "\n",
    "            # POSSIBLE payoff\n",
    "            for strategy in xrange(len(gego.node[inode]['plays'])):\n",
    "                gego.node[inode]['possible_play'] = gego.node[inode]['plays'][strategy]\n",
    "                for neighbor in xrange(len(gego.node[inode]['neighbors'])):\n",
    "                    if gego.node[gego.node[inode]['neighbors'][neighbor]]['current_play'] == gego.node[inode]['possible_play']:\n",
    "                         pp += 1\n",
    "                pps.append(pp)\n",
    "                pp = 0\n",
    "\n",
    "            # Find strategy giving best payoff and update 'current_play' according to it\n",
    "            if np.max(pps) > curr_payoff:\n",
    "                # randomize strategy if max payoffs repeat\n",
    "                max_payoff_indices = [i for i, x in enumerate(pps) if x == max(pps)]\n",
    "                random_index = random.choice(max_payoff_indices)\n",
    "                # assign new strategy\n",
    "                gego.node[inode]['current_play'] = gego.node[inode]['plays'][random_index]\n",
    "                opt_new_strategies[inode] = gego.node[inode]['current_play']\n",
    "\n",
    "    ### CALCULATE SOCIAL WELFARE ###\n",
    "\n",
    "\n",
    "    # initialize list with all players' payoffs\n",
    "    opt_ind_payoffs = []\n",
    "    for inode in xrange(len(nodeIDs)):\n",
    "        opt_ind_payoff = 0\n",
    "        for neighbor in xrange(len(gego.node[inode]['neighbors'])):\n",
    "            if gego.node[gego.node[inode]['neighbors'][neighbor]]['current_play'] == gego.node[inode]['current_play']:\n",
    "                opt_ind_payoff += 1\n",
    "        opt_ind_payoffs.append(opt_ind_payoff)\n",
    "\n",
    "    opt_social_welfare = sum(opt_ind_payoffs)\n",
    "\n",
    "    if float(social_welfare) != 0:\n",
    "        PoA = float(opt_social_welfare) / float(social_welfare)\n",
    "    elif float(social_welfare) == 0:\n",
    "        PoA = float('inf')\n",
    "\n",
    "    ### 3\n",
    "    # add data to dataframe k | k size | PoA\n",
    "    df2 = pd.DataFrame([[k, len(k), social_welfare, opt_social_welfare, PoA ]], columns=('k', 'k size', 'SW', 'reasonable SW', 'PoA'))\n",
    "    frames = [data, df2]\n",
    "    data = pd.concat(frames)\n",
    "data.to_csv('FB4-random-k%s.csv' %str(len(k)), encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# |K| = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### EXPERIMENT K size = 9\n",
    "\n",
    "sizes = [1,3,4,5,6,7,8,9,10]\n",
    "# for j in xrange(len(sizes)): #for different sizes of k\n",
    "    # initialize dataframe k | k size | PoA\n",
    "data = pd.DataFrame(columns=('k', 'k size', 'PoA'))\n",
    "    ### 1\n",
    "\n",
    "    #random K set\n",
    "    #k = random.sample(xrange(len(nodeIDs)), sizes[j])\n",
    "\n",
    "for i in xrange(200):\n",
    "    ### 1\n",
    "\n",
    "    #random K set\n",
    "    k = random.sample(xrange(len(nodeIDs)), sizes[7])\n",
    "\n",
    "    ### 2\n",
    "\n",
    "    #ADD ALL CALCULATIONS FOR THIS k\n",
    "    grd = grdict.copy()\n",
    "    gdc = copy.copy(grd)\n",
    "    # make dictionary into graph\n",
    "    grd = nx.to_networkx_graph(grd)\n",
    "\n",
    "    ############## START STRATEGY DISTRIBUTION ###########\n",
    "\n",
    "    ### Initialize Identity matrix - everyone has their own strategy\n",
    "\n",
    "    strategies = np.identity(len(nodeIDs))\n",
    "\n",
    "    ### Make a copy of real graph to find strategy distribution (because we'll need to delete some edges)\n",
    "\n",
    "    H = grd.copy()\n",
    "\n",
    "    ### For strategy distribution disregard edges between nodes in k\n",
    "\n",
    "    #all possible edge combinations between the k_nodes\n",
    "    knode_pedges=list(itertools.combinations(k, 2))\n",
    "\n",
    "    #Identify if the nodes have edges among each other and store them\n",
    "    edges_between_k=[]\n",
    "    for pedge in knode_pedges:\n",
    "        for edge in H.edges():\n",
    "            if set(pedge)==set(edge):\n",
    "                edges_between_k.append(pedge)\n",
    "\n",
    "    # For the strategy distribution delete the edges between k in a duplicate H of our real graph grd! \n",
    "    H.remove_edges_from(edges_between_k)\n",
    "\n",
    "    ### Find neighborhood of range = 2 for nodes in k and assign them the strategy of that node\n",
    "\n",
    "    #Check how many nodes have neighborhood of 2 less than a 100\n",
    "\n",
    "    for i in xrange(len(k)):\n",
    "        for j in nx.ego_graph(H, k[i], 2).nodes():\n",
    "            if j not in k:\n",
    "                strategies[j][k[i]]=1\n",
    "\n",
    "    np.where(strategies[4] == 1)[0].tolist()\n",
    "\n",
    "    ### STRATEGY ASSIGNMENT TO NODES\n",
    "\n",
    "    #to avoid confusion attribute will be called plays rather than strategies (to separate from strategy matrix)\n",
    "\n",
    "    for i in xrange(len(nodeIDs)):\n",
    "        key=\"plays\"\n",
    "        #step of assigining attributes\n",
    "        grd.node[i].setdefault(key, np.where(strategies[i] == 1)[0].tolist()) \n",
    "\n",
    "    gego = grd.copy() # duplicate graph for 'OPTIMAL' calculations later\n",
    "\n",
    "    ### Create ATTRIBUTES in graph: neighbors, current_play, possible_play (to find what is my payoff \n",
    "    #                                                                       if I play this strategy)\n",
    "\n",
    "    for i in xrange(len(nodeIDs)):\n",
    "        # step of assigining attributes\n",
    "        grd.node[i].setdefault(\"neighbors\", gdc[i])\n",
    "        # everybody starts at their own strategy; 'possible_play' attribute for strategy update\n",
    "        grd.node[i].setdefault(\"current_play\", i)\n",
    "        grd.node[i].setdefault(\"possible_play\", i)\n",
    "\n",
    "    ### UPDATE STRATEGIES ### \n",
    "\n",
    "    # the idea is to have two strategy lists that will be compared after every iteration through all the nodes\n",
    "    # when the lists are identical, no player will switch strategies -> hence, Nash equilibrium\n",
    "\n",
    "\n",
    "    # Initialize two lists to compare \n",
    "    past_strategies = []\n",
    "    new_strategies = []\n",
    "    for i in xrange(len(nodeIDs)):\n",
    "        new_strategies.append(grd.node[i]['current_play'])\n",
    "        past_strategies.append(0)\n",
    "\n",
    "\n",
    "    ### WHILE LOOP TO FIND BEST STRATEGIES ###\n",
    "\n",
    "\n",
    "    i = 0\n",
    "    while past_strategies != new_strategies:\n",
    "        past_strategies = copy.copy(new_strategies)\n",
    "        for inode in xrange(len(nodeIDs)):\n",
    "            # current payoff initialization\n",
    "            curr_payoff = 0\n",
    "            # possible payoff/list of payoffs initialize for every node\n",
    "            pp = 0\n",
    "            pps = []\n",
    "\n",
    "            # CURRENT payoff\n",
    "            for neighbor in xrange(len(grd.node[inode]['neighbors'])):\n",
    "                if grd.node[grd.node[inode]['neighbors'][neighbor]]['current_play'] == grd.node[inode]['current_play']:\n",
    "                    curr_payoff += 1\n",
    "\n",
    "            # POSSIBLE payoff\n",
    "            for strategy in xrange(len(grd.node[inode]['plays'])):\n",
    "                grd.node[inode]['possible_play'] = grd.node[inode]['plays'][strategy]\n",
    "                for neighbor in xrange(len(grd.node[inode]['neighbors'])):\n",
    "                    if grd.node[grd.node[inode]['neighbors'][neighbor]]['current_play'] == grd.node[inode]['possible_play']:\n",
    "                         pp += 1\n",
    "                pps.append(pp)\n",
    "                pp = 0\n",
    "\n",
    "            # Find strategy giving best payoff and update 'current_play' according to it\n",
    "            if np.max(pps) > curr_payoff:\n",
    "                # randomize strategy if max payoffs repeat\n",
    "                max_payoff_indices = [i for i, x in enumerate(pps) if x == max(pps)]\n",
    "                random_index = random.choice(max_payoff_indices)\n",
    "                # assign new strategy\n",
    "                grd.node[inode]['current_play'] = grd.node[inode]['plays'][random_index]\n",
    "                new_strategies[inode] = grd.node[inode]['current_play']\n",
    "\n",
    "    ### CALCULATE SOCIAL WELFARE ###\n",
    "\n",
    "\n",
    "    # initialize list with all players' payoffs\n",
    "    ind_payoffs = []\n",
    "    for inode in xrange(len(nodeIDs)):\n",
    "        ind_payoff = 0\n",
    "        for neighbor in xrange(len(grd.node[inode]['neighbors'])):\n",
    "            if grd.node[grd.node[inode]['neighbors'][neighbor]]['current_play'] == grd.node[inode]['current_play']:\n",
    "                ind_payoff += 1\n",
    "        ind_payoffs.append(ind_payoff)\n",
    "\n",
    "    social_welfare = sum(ind_payoffs)\n",
    "\n",
    "    ### OPTIMAL WELFARE APPROXIMATION ###\n",
    "\n",
    "    source_neighborhoods = []\n",
    "\n",
    "    # choose source with biggest ego_network\n",
    "    for source in xrange(len(k)):\n",
    "        source_neighborhoods.append(len(nx.ego_graph(gego, k[source], 2).nodes()))\n",
    "\n",
    "    for node in xrange(len(nodeIDs)):\n",
    "        gego.node[node][\"neighbors\"] = gdc[node]\n",
    "        if node in nx.ego_graph(gego, np.max(source_neighborhoods), 2).nodes():\n",
    "            # every node in ego graph gets only one strategy (source's strategy)\n",
    "            gego.node[node][\"current_play\"] = k[np.argmax(source_neighborhoods)]\n",
    "            gego.node[node][\"possible_play\"] = k[np.argmax(source_neighborhoods)]\n",
    "            gego.node[node][\"plays\"] = [k[np.argmax(source_neighborhoods)]]\n",
    "        elif node not in nx.ego_graph(gego, np.max(source_neighborhoods), 2).nodes():\n",
    "        #    # prepare for best response\n",
    "            gego.node[node][\"current_play\"] = node\n",
    "            gego.node[node][\"possible_play\"] = node\n",
    "\n",
    "    opt_past_strategies = [] # Initialize two lists to compare \n",
    "    opt_new_strategies = []\n",
    "    for i in xrange(len(nodeIDs)):\n",
    "        opt_new_strategies.append(gego.node[i]['current_play'])\n",
    "        opt_past_strategies.append(0)\n",
    "\n",
    "\n",
    "    ### While loop to find best strategies ###\n",
    "\n",
    "\n",
    "    while opt_past_strategies != opt_new_strategies:\n",
    "        opt_past_strategies = copy.copy(opt_new_strategies)\n",
    "        for inode in xrange(len(nodeIDs)):\n",
    "            # current payoff initialization\n",
    "            curr_payoff = 0\n",
    "            # possible payoff/list of payoffs initialize for every node\n",
    "            pp = 0\n",
    "            pps = []\n",
    "\n",
    "            # CURRENT payoff\n",
    "            for neighbor in xrange(len(gego.node[inode]['neighbors'])):\n",
    "                if gego.node[gego.node[inode]['neighbors'][neighbor]]['current_play'] == gego.node[inode]['current_play']:\n",
    "                    curr_payoff += 1\n",
    "\n",
    "            # POSSIBLE payoff\n",
    "            for strategy in xrange(len(gego.node[inode]['plays'])):\n",
    "                gego.node[inode]['possible_play'] = gego.node[inode]['plays'][strategy]\n",
    "                for neighbor in xrange(len(gego.node[inode]['neighbors'])):\n",
    "                    if gego.node[gego.node[inode]['neighbors'][neighbor]]['current_play'] == gego.node[inode]['possible_play']:\n",
    "                         pp += 1\n",
    "                pps.append(pp)\n",
    "                pp = 0\n",
    "\n",
    "            # Find strategy giving best payoff and update 'current_play' according to it\n",
    "            if np.max(pps) > curr_payoff:\n",
    "                # randomize strategy if max payoffs repeat\n",
    "                max_payoff_indices = [i for i, x in enumerate(pps) if x == max(pps)]\n",
    "                random_index = random.choice(max_payoff_indices)\n",
    "                # assign new strategy\n",
    "                gego.node[inode]['current_play'] = gego.node[inode]['plays'][random_index]\n",
    "                opt_new_strategies[inode] = gego.node[inode]['current_play']\n",
    "\n",
    "    ### CALCULATE SOCIAL WELFARE ###\n",
    "\n",
    "\n",
    "    # initialize list with all players' payoffs\n",
    "    opt_ind_payoffs = []\n",
    "    for inode in xrange(len(nodeIDs)):\n",
    "        opt_ind_payoff = 0\n",
    "        for neighbor in xrange(len(gego.node[inode]['neighbors'])):\n",
    "            if gego.node[gego.node[inode]['neighbors'][neighbor]]['current_play'] == gego.node[inode]['current_play']:\n",
    "                opt_ind_payoff += 1\n",
    "        opt_ind_payoffs.append(opt_ind_payoff)\n",
    "\n",
    "    opt_social_welfare = sum(opt_ind_payoffs)\n",
    "\n",
    "    if float(social_welfare) != 0:\n",
    "        PoA = float(opt_social_welfare) / float(social_welfare)\n",
    "    elif float(social_welfare) == 0:\n",
    "        PoA = float('inf')\n",
    "\n",
    "    ### 3\n",
    "    # add data to dataframe k | k size | PoA\n",
    "    df2 = pd.DataFrame([[k, len(k), social_welfare, opt_social_welfare, PoA ]], columns=('k', 'k size', 'SW', 'reasonable SW', 'PoA'))\n",
    "    frames = [data, df2]\n",
    "    data = pd.concat(frames)\n",
    "data.to_csv('FB4-random-k%s.csv' %str(len(k)), encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# |K| = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### EXPERIMENT K size = 10\n",
    "\n",
    "sizes = [1,3,4,5,6,7,8,9,10]\n",
    "# for j in xrange(len(sizes)): #for different sizes of k\n",
    "    # initialize dataframe k | k size | PoA\n",
    "data = pd.DataFrame(columns=('k', 'k size', 'PoA'))\n",
    "    ### 1\n",
    "\n",
    "    #random K set\n",
    "    #k = random.sample(xrange(len(nodeIDs)), sizes[j])\n",
    "\n",
    "for i in xrange(200):\n",
    "    ### 1\n",
    "\n",
    "    #random K set\n",
    "    k = random.sample(xrange(len(nodeIDs)), sizes[8])\n",
    "\n",
    "    ### 2\n",
    "\n",
    "    #ADD ALL CALCULATIONS FOR THIS k\n",
    "    grd = grdict.copy()\n",
    "    gdc = copy.copy(grd)\n",
    "    # make dictionary into graph\n",
    "    grd = nx.to_networkx_graph(grd)\n",
    "\n",
    "    ############## START STRATEGY DISTRIBUTION ###########\n",
    "\n",
    "    ### Initialize Identity matrix - everyone has their own strategy\n",
    "\n",
    "    strategies = np.identity(len(nodeIDs))\n",
    "\n",
    "    ### Make a copy of real graph to find strategy distribution (because we'll need to delete some edges)\n",
    "\n",
    "    H = grd.copy()\n",
    "\n",
    "    ### For strategy distribution disregard edges between nodes in k\n",
    "\n",
    "    #all possible edge combinations between the k_nodes\n",
    "    knode_pedges=list(itertools.combinations(k, 2))\n",
    "\n",
    "    #Identify if the nodes have edges among each other and store them\n",
    "    edges_between_k=[]\n",
    "    for pedge in knode_pedges:\n",
    "        for edge in H.edges():\n",
    "            if set(pedge)==set(edge):\n",
    "                edges_between_k.append(pedge)\n",
    "\n",
    "    # For the strategy distribution delete the edges between k in a duplicate H of our real graph grd! \n",
    "    H.remove_edges_from(edges_between_k)\n",
    "\n",
    "    ### Find neighborhood of range = 2 for nodes in k and assign them the strategy of that node\n",
    "\n",
    "    #Check how many nodes have neighborhood of 2 less than a 100\n",
    "\n",
    "    for i in xrange(len(k)):\n",
    "        for j in nx.ego_graph(H, k[i], 2).nodes():\n",
    "            if j not in k:\n",
    "                strategies[j][k[i]]=1\n",
    "\n",
    "    np.where(strategies[4] == 1)[0].tolist()\n",
    "\n",
    "    ### STRATEGY ASSIGNMENT TO NODES\n",
    "\n",
    "    #to avoid confusion attribute will be called plays rather than strategies (to separate from strategy matrix)\n",
    "\n",
    "    for i in xrange(len(nodeIDs)):\n",
    "        key=\"plays\"\n",
    "        #step of assigining attributes\n",
    "        grd.node[i].setdefault(key, np.where(strategies[i] == 1)[0].tolist()) \n",
    "\n",
    "    gego = grd.copy() # duplicate graph for 'OPTIMAL' calculations later\n",
    "\n",
    "    ### Create ATTRIBUTES in graph: neighbors, current_play, possible_play (to find what is my payoff \n",
    "    #                                                                       if I play this strategy)\n",
    "\n",
    "    for i in xrange(len(nodeIDs)):\n",
    "        # step of assigining attributes\n",
    "        grd.node[i].setdefault(\"neighbors\", gdc[i])\n",
    "        # everybody starts at their own strategy; 'possible_play' attribute for strategy update\n",
    "        grd.node[i].setdefault(\"current_play\", i)\n",
    "        grd.node[i].setdefault(\"possible_play\", i)\n",
    "\n",
    "    ### UPDATE STRATEGIES ### \n",
    "\n",
    "    # the idea is to have two strategy lists that will be compared after every iteration through all the nodes\n",
    "    # when the lists are identical, no player will switch strategies -> hence, Nash equilibrium\n",
    "\n",
    "\n",
    "    # Initialize two lists to compare \n",
    "    past_strategies = []\n",
    "    new_strategies = []\n",
    "    for i in xrange(len(nodeIDs)):\n",
    "        new_strategies.append(grd.node[i]['current_play'])\n",
    "        past_strategies.append(0)\n",
    "\n",
    "\n",
    "    ### WHILE LOOP TO FIND BEST STRATEGIES ###\n",
    "\n",
    "\n",
    "    i = 0\n",
    "    while past_strategies != new_strategies:\n",
    "        past_strategies = copy.copy(new_strategies)\n",
    "        for inode in xrange(len(nodeIDs)):\n",
    "            # current payoff initialization\n",
    "            curr_payoff = 0\n",
    "            # possible payoff/list of payoffs initialize for every node\n",
    "            pp = 0\n",
    "            pps = []\n",
    "\n",
    "            # CURRENT payoff\n",
    "            for neighbor in xrange(len(grd.node[inode]['neighbors'])):\n",
    "                if grd.node[grd.node[inode]['neighbors'][neighbor]]['current_play'] == grd.node[inode]['current_play']:\n",
    "                    curr_payoff += 1\n",
    "\n",
    "            # POSSIBLE payoff\n",
    "            for strategy in xrange(len(grd.node[inode]['plays'])):\n",
    "                grd.node[inode]['possible_play'] = grd.node[inode]['plays'][strategy]\n",
    "                for neighbor in xrange(len(grd.node[inode]['neighbors'])):\n",
    "                    if grd.node[grd.node[inode]['neighbors'][neighbor]]['current_play'] == grd.node[inode]['possible_play']:\n",
    "                         pp += 1\n",
    "                pps.append(pp)\n",
    "                pp = 0\n",
    "\n",
    "            # Find strategy giving best payoff and update 'current_play' according to it\n",
    "            if np.max(pps) > curr_payoff:\n",
    "                # randomize strategy if max payoffs repeat\n",
    "                max_payoff_indices = [i for i, x in enumerate(pps) if x == max(pps)]\n",
    "                random_index = random.choice(max_payoff_indices)\n",
    "                # assign new strategy\n",
    "                grd.node[inode]['current_play'] = grd.node[inode]['plays'][random_index]\n",
    "                new_strategies[inode] = grd.node[inode]['current_play']\n",
    "\n",
    "    ### CALCULATE SOCIAL WELFARE ###\n",
    "\n",
    "\n",
    "    # initialize list with all players' payoffs\n",
    "    ind_payoffs = []\n",
    "    for inode in xrange(len(nodeIDs)):\n",
    "        ind_payoff = 0\n",
    "        for neighbor in xrange(len(grd.node[inode]['neighbors'])):\n",
    "            if grd.node[grd.node[inode]['neighbors'][neighbor]]['current_play'] == grd.node[inode]['current_play']:\n",
    "                ind_payoff += 1\n",
    "        ind_payoffs.append(ind_payoff)\n",
    "\n",
    "    social_welfare = sum(ind_payoffs)\n",
    "\n",
    "    ### OPTIMAL WELFARE APPROXIMATION ###\n",
    "\n",
    "    source_neighborhoods = []\n",
    "\n",
    "    # choose source with biggest ego_network\n",
    "    for source in xrange(len(k)):\n",
    "        source_neighborhoods.append(len(nx.ego_graph(gego, k[source], 2).nodes()))\n",
    "\n",
    "    for node in xrange(len(nodeIDs)):\n",
    "        gego.node[node][\"neighbors\"] = gdc[node]\n",
    "        if node in nx.ego_graph(gego, np.max(source_neighborhoods), 2).nodes():\n",
    "            # every node in ego graph gets only one strategy (source's strategy)\n",
    "            gego.node[node][\"current_play\"] = k[np.argmax(source_neighborhoods)]\n",
    "            gego.node[node][\"possible_play\"] = k[np.argmax(source_neighborhoods)]\n",
    "            gego.node[node][\"plays\"] = [k[np.argmax(source_neighborhoods)]]\n",
    "        elif node not in nx.ego_graph(gego, np.max(source_neighborhoods), 2).nodes():\n",
    "        #    # prepare for best response\n",
    "            gego.node[node][\"current_play\"] = node\n",
    "            gego.node[node][\"possible_play\"] = node\n",
    "\n",
    "    opt_past_strategies = [] # Initialize two lists to compare \n",
    "    opt_new_strategies = []\n",
    "    for i in xrange(len(nodeIDs)):\n",
    "        opt_new_strategies.append(gego.node[i]['current_play'])\n",
    "        opt_past_strategies.append(0)\n",
    "\n",
    "\n",
    "    ### While loop to find best strategies ###\n",
    "\n",
    "\n",
    "    while opt_past_strategies != opt_new_strategies:\n",
    "        opt_past_strategies = copy.copy(opt_new_strategies)\n",
    "        for inode in xrange(len(nodeIDs)):\n",
    "            # current payoff initialization\n",
    "            curr_payoff = 0\n",
    "            # possible payoff/list of payoffs initialize for every node\n",
    "            pp = 0\n",
    "            pps = []\n",
    "\n",
    "            # CURRENT payoff\n",
    "            for neighbor in xrange(len(gego.node[inode]['neighbors'])):\n",
    "                if gego.node[gego.node[inode]['neighbors'][neighbor]]['current_play'] == gego.node[inode]['current_play']:\n",
    "                    curr_payoff += 1\n",
    "\n",
    "            # POSSIBLE payoff\n",
    "            for strategy in xrange(len(gego.node[inode]['plays'])):\n",
    "                gego.node[inode]['possible_play'] = gego.node[inode]['plays'][strategy]\n",
    "                for neighbor in xrange(len(gego.node[inode]['neighbors'])):\n",
    "                    if gego.node[gego.node[inode]['neighbors'][neighbor]]['current_play'] == gego.node[inode]['possible_play']:\n",
    "                         pp += 1\n",
    "                pps.append(pp)\n",
    "                pp = 0\n",
    "\n",
    "            # Find strategy giving best payoff and update 'current_play' according to it\n",
    "            if np.max(pps) > curr_payoff:\n",
    "                # randomize strategy if max payoffs repeat\n",
    "                max_payoff_indices = [i for i, x in enumerate(pps) if x == max(pps)]\n",
    "                random_index = random.choice(max_payoff_indices)\n",
    "                # assign new strategy\n",
    "                gego.node[inode]['current_play'] = gego.node[inode]['plays'][random_index]\n",
    "                opt_new_strategies[inode] = gego.node[inode]['current_play']\n",
    "\n",
    "    ### CALCULATE SOCIAL WELFARE ###\n",
    "\n",
    "\n",
    "    # initialize list with all players' payoffs\n",
    "    opt_ind_payoffs = []\n",
    "    for inode in xrange(len(nodeIDs)):\n",
    "        opt_ind_payoff = 0\n",
    "        for neighbor in xrange(len(gego.node[inode]['neighbors'])):\n",
    "            if gego.node[gego.node[inode]['neighbors'][neighbor]]['current_play'] == gego.node[inode]['current_play']:\n",
    "                opt_ind_payoff += 1\n",
    "        opt_ind_payoffs.append(opt_ind_payoff)\n",
    "\n",
    "    opt_social_welfare = sum(opt_ind_payoffs)\n",
    "\n",
    "    if float(social_welfare) != 0:\n",
    "        PoA = float(opt_social_welfare) / float(social_welfare)\n",
    "    elif float(social_welfare) == 0:\n",
    "        PoA = float('inf')\n",
    "\n",
    "    ### 3\n",
    "    # add data to dataframe k | k size | PoA\n",
    "    df2 = pd.DataFrame([[k, len(k), social_welfare, opt_social_welfare, PoA ]], columns=('k', 'k size', 'SW', 'reasonable SW', 'PoA'))\n",
    "    frames = [data, df2]\n",
    "    data = pd.concat(frames)\n",
    "data.to_csv('FB4-random-k%s.csv' %str(len(k)), encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# |K| = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### EXPERIMENT K size = 2\n",
    "\n",
    "sizes = [1,3,4,5,6,7,8,9,10,2]\n",
    "# for j in xrange(len(sizes)): #for different sizes of k\n",
    "    # initialize dataframe k | k size | PoA\n",
    "data = pd.DataFrame(columns=('k', 'k size', 'PoA'))\n",
    "    ### 1\n",
    "\n",
    "    #random K set\n",
    "    #k = random.sample(xrange(len(nodeIDs)), sizes[j])\n",
    "\n",
    "for i in xrange(200):\n",
    "    ### 1\n",
    "\n",
    "    #random K set\n",
    "    k = random.sample(xrange(len(nodeIDs)), sizes[9])\n",
    "\n",
    "    ### 2\n",
    "\n",
    "    #ADD ALL CALCULATIONS FOR THIS k\n",
    "    grd = grdict.copy()\n",
    "    gdc = copy.copy(grd)\n",
    "    # make dictionary into graph\n",
    "    grd = nx.to_networkx_graph(grd)\n",
    "\n",
    "    ############## START STRATEGY DISTRIBUTION ###########\n",
    "\n",
    "    ### Initialize Identity matrix - everyone has their own strategy\n",
    "\n",
    "    strategies = np.identity(len(nodeIDs))\n",
    "\n",
    "    ### Make a copy of real graph to find strategy distribution (because we'll need to delete some edges)\n",
    "\n",
    "    H = grd.copy()\n",
    "\n",
    "    ### For strategy distribution disregard edges between nodes in k\n",
    "\n",
    "    #all possible edge combinations between the k_nodes\n",
    "    knode_pedges=list(itertools.combinations(k, 2))\n",
    "\n",
    "    #Identify if the nodes have edges among each other and store them\n",
    "    edges_between_k=[]\n",
    "    for pedge in knode_pedges:\n",
    "        for edge in H.edges():\n",
    "            if set(pedge)==set(edge):\n",
    "                edges_between_k.append(pedge)\n",
    "\n",
    "    # For the strategy distribution delete the edges between k in a duplicate H of our real graph grd! \n",
    "    H.remove_edges_from(edges_between_k)\n",
    "\n",
    "    ### Find neighborhood of range = 2 for nodes in k and assign them the strategy of that node\n",
    "\n",
    "    #Check how many nodes have neighborhood of 2 less than a 100\n",
    "\n",
    "    for i in xrange(len(k)):\n",
    "        for j in nx.ego_graph(H, k[i], 2).nodes():\n",
    "            if j not in k:\n",
    "                strategies[j][k[i]]=1\n",
    "\n",
    "    np.where(strategies[4] == 1)[0].tolist()\n",
    "\n",
    "    ### STRATEGY ASSIGNMENT TO NODES\n",
    "\n",
    "    #to avoid confusion attribute will be called plays rather than strategies (to separate from strategy matrix)\n",
    "\n",
    "    for i in xrange(len(nodeIDs)):\n",
    "        key=\"plays\"\n",
    "        #step of assigining attributes\n",
    "        grd.node[i].setdefault(key, np.where(strategies[i] == 1)[0].tolist()) \n",
    "\n",
    "    gego = grd.copy() # duplicate graph for 'OPTIMAL' calculations later\n",
    "\n",
    "    ### Create ATTRIBUTES in graph: neighbors, current_play, possible_play (to find what is my payoff \n",
    "    #                                                                       if I play this strategy)\n",
    "\n",
    "    for i in xrange(len(nodeIDs)):\n",
    "        # step of assigining attributes\n",
    "        grd.node[i].setdefault(\"neighbors\", gdc[i])\n",
    "        # everybody starts at their own strategy; 'possible_play' attribute for strategy update\n",
    "        grd.node[i].setdefault(\"current_play\", i)\n",
    "        grd.node[i].setdefault(\"possible_play\", i)\n",
    "\n",
    "    ### UPDATE STRATEGIES ### \n",
    "\n",
    "    # the idea is to have two strategy lists that will be compared after every iteration through all the nodes\n",
    "    # when the lists are identical, no player will switch strategies -> hence, Nash equilibrium\n",
    "\n",
    "\n",
    "    # Initialize two lists to compare \n",
    "    past_strategies = []\n",
    "    new_strategies = []\n",
    "    for i in xrange(len(nodeIDs)):\n",
    "        new_strategies.append(grd.node[i]['current_play'])\n",
    "        past_strategies.append(0)\n",
    "\n",
    "\n",
    "    ### WHILE LOOP TO FIND BEST STRATEGIES ###\n",
    "\n",
    "\n",
    "    i = 0\n",
    "    while past_strategies != new_strategies:\n",
    "        past_strategies = copy.copy(new_strategies)\n",
    "        for inode in xrange(len(nodeIDs)):\n",
    "            # current payoff initialization\n",
    "            curr_payoff = 0\n",
    "            # possible payoff/list of payoffs initialize for every node\n",
    "            pp = 0\n",
    "            pps = []\n",
    "\n",
    "            # CURRENT payoff\n",
    "            for neighbor in xrange(len(grd.node[inode]['neighbors'])):\n",
    "                if grd.node[grd.node[inode]['neighbors'][neighbor]]['current_play'] == grd.node[inode]['current_play']:\n",
    "                    curr_payoff += 1\n",
    "\n",
    "            # POSSIBLE payoff\n",
    "            for strategy in xrange(len(grd.node[inode]['plays'])):\n",
    "                grd.node[inode]['possible_play'] = grd.node[inode]['plays'][strategy]\n",
    "                for neighbor in xrange(len(grd.node[inode]['neighbors'])):\n",
    "                    if grd.node[grd.node[inode]['neighbors'][neighbor]]['current_play'] == grd.node[inode]['possible_play']:\n",
    "                         pp += 1\n",
    "                pps.append(pp)\n",
    "                pp = 0\n",
    "\n",
    "            # Find strategy giving best payoff and update 'current_play' according to it\n",
    "            if np.max(pps) > curr_payoff:\n",
    "                # randomize strategy if max payoffs repeat\n",
    "                max_payoff_indices = [i for i, x in enumerate(pps) if x == max(pps)]\n",
    "                random_index = random.choice(max_payoff_indices)\n",
    "                # assign new strategy\n",
    "                grd.node[inode]['current_play'] = grd.node[inode]['plays'][random_index]\n",
    "                new_strategies[inode] = grd.node[inode]['current_play']\n",
    "\n",
    "    ### CALCULATE SOCIAL WELFARE ###\n",
    "\n",
    "\n",
    "    # initialize list with all players' payoffs\n",
    "    ind_payoffs = []\n",
    "    for inode in xrange(len(nodeIDs)):\n",
    "        ind_payoff = 0\n",
    "        for neighbor in xrange(len(grd.node[inode]['neighbors'])):\n",
    "            if grd.node[grd.node[inode]['neighbors'][neighbor]]['current_play'] == grd.node[inode]['current_play']:\n",
    "                ind_payoff += 1\n",
    "        ind_payoffs.append(ind_payoff)\n",
    "\n",
    "    social_welfare = sum(ind_payoffs)\n",
    "\n",
    "    ### OPTIMAL WELFARE APPROXIMATION ###\n",
    "\n",
    "    source_neighborhoods = []\n",
    "\n",
    "    # choose source with biggest ego_network\n",
    "    for source in xrange(len(k)):\n",
    "        source_neighborhoods.append(len(nx.ego_graph(gego, k[source], 2).nodes()))\n",
    "\n",
    "    for node in xrange(len(nodeIDs)):\n",
    "        gego.node[node][\"neighbors\"] = gdc[node]\n",
    "        if node in nx.ego_graph(gego, np.max(source_neighborhoods), 2).nodes():\n",
    "            # every node in ego graph gets only one strategy (source's strategy)\n",
    "            gego.node[node][\"current_play\"] = k[np.argmax(source_neighborhoods)]\n",
    "            gego.node[node][\"possible_play\"] = k[np.argmax(source_neighborhoods)]\n",
    "            gego.node[node][\"plays\"] = [k[np.argmax(source_neighborhoods)]]\n",
    "        elif node not in nx.ego_graph(gego, np.max(source_neighborhoods), 2).nodes():\n",
    "        #    # prepare for best response\n",
    "            gego.node[node][\"current_play\"] = node\n",
    "            gego.node[node][\"possible_play\"] = node\n",
    "\n",
    "    opt_past_strategies = [] # Initialize two lists to compare \n",
    "    opt_new_strategies = []\n",
    "    for i in xrange(len(nodeIDs)):\n",
    "        opt_new_strategies.append(gego.node[i]['current_play'])\n",
    "        opt_past_strategies.append(0)\n",
    "\n",
    "\n",
    "    ### While loop to find best strategies ###\n",
    "\n",
    "\n",
    "    while opt_past_strategies != opt_new_strategies:\n",
    "        opt_past_strategies = copy.copy(opt_new_strategies)\n",
    "        for inode in xrange(len(nodeIDs)):\n",
    "            # current payoff initialization\n",
    "            curr_payoff = 0\n",
    "            # possible payoff/list of payoffs initialize for every node\n",
    "            pp = 0\n",
    "            pps = []\n",
    "\n",
    "            # CURRENT payoff\n",
    "            for neighbor in xrange(len(gego.node[inode]['neighbors'])):\n",
    "                if gego.node[gego.node[inode]['neighbors'][neighbor]]['current_play'] == gego.node[inode]['current_play']:\n",
    "                    curr_payoff += 1\n",
    "\n",
    "            # POSSIBLE payoff\n",
    "            for strategy in xrange(len(gego.node[inode]['plays'])):\n",
    "                gego.node[inode]['possible_play'] = gego.node[inode]['plays'][strategy]\n",
    "                for neighbor in xrange(len(gego.node[inode]['neighbors'])):\n",
    "                    if gego.node[gego.node[inode]['neighbors'][neighbor]]['current_play'] == gego.node[inode]['possible_play']:\n",
    "                         pp += 1\n",
    "                pps.append(pp)\n",
    "                pp = 0\n",
    "\n",
    "            # Find strategy giving best payoff and update 'current_play' according to it\n",
    "            if np.max(pps) > curr_payoff:\n",
    "                # randomize strategy if max payoffs repeat\n",
    "                max_payoff_indices = [i for i, x in enumerate(pps) if x == max(pps)]\n",
    "                random_index = random.choice(max_payoff_indices)\n",
    "                # assign new strategy\n",
    "                gego.node[inode]['current_play'] = gego.node[inode]['plays'][random_index]\n",
    "                opt_new_strategies[inode] = gego.node[inode]['current_play']\n",
    "\n",
    "    ### CALCULATE SOCIAL WELFARE ###\n",
    "\n",
    "\n",
    "    # initialize list with all players' payoffs\n",
    "    opt_ind_payoffs = []\n",
    "    for inode in xrange(len(nodeIDs)):\n",
    "        opt_ind_payoff = 0\n",
    "        for neighbor in xrange(len(gego.node[inode]['neighbors'])):\n",
    "            if gego.node[gego.node[inode]['neighbors'][neighbor]]['current_play'] == gego.node[inode]['current_play']:\n",
    "                opt_ind_payoff += 1\n",
    "        opt_ind_payoffs.append(opt_ind_payoff)\n",
    "\n",
    "    opt_social_welfare = sum(opt_ind_payoffs)\n",
    "\n",
    "    if float(social_welfare) != 0:\n",
    "        PoA = float(opt_social_welfare) / float(social_welfare)\n",
    "    elif float(social_welfare) == 0:\n",
    "        PoA = float('inf')\n",
    "\n",
    "    ### 3\n",
    "    # add data to dataframe k | k size | PoA\n",
    "    df2 = pd.DataFrame([[k, len(k), social_welfare, opt_social_welfare, PoA ]], columns=('k', 'k size', 'SW', 'reasonable SW', 'PoA'))\n",
    "    frames = [data, df2]\n",
    "    data = pd.concat(frames)\n",
    "data.to_csv('FB4-random-k%s.csv' %str(len(k)), encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
